{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852d743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.10)\n",
      "Requirement already satisfied: awscli in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.24.10)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (8.0.0)\n",
      "Requirement already satisfied: torchbnn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.10 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.16)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (1.26.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (9.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (1.22.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (2.27.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.24.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (62.3.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 6)) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.9/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.0.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.2.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31c03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "import socket\n",
    "from botocore.handlers import disable_signing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b808858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if socket.gethostname() == 'Rohits-MBP':\n",
    "    rootdir = '/Users/rohitchanne/Documents/capstone/data/data_parquet/'\n",
    "else: \n",
    "    rootdir = '' # Enter your hone dir here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0d4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = filter( os.path.isfile, glob.glob(rootdir + '*') )\n",
    "files_with_size = [ file_path for file_path in list_of_files ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2717cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data File: Wednesday-21-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-23-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thuesday-20-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-22-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-16-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-28-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-14-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-15-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-01-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-02-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "dfs_parquet = {}\n",
    "for file_path in files_with_size:\n",
    "    if 'parquet' in file_path:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        df_name = file_name.split('_')[0]\n",
    "        print(f'Reading Data File: {file_name}')       \n",
    "        dfs_parquet[df_name] = pd.read_parquet(file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e52ca72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_parquet['Thuesday-20-02-2018'].drop(['Flow ID', 'Src IP', 'Src Port', 'Dst IP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39af725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wednesday-21-02-2018\n",
      "DF:Wednesday-21-02-2018, Shape(1048575, 80)\n",
      "Friday-23-02-2018\n",
      "DF:Friday-23-02-2018, Shape(1048575, 80)\n",
      "Thuesday-20-02-2018\n",
      "DF:Thuesday-20-02-2018, Shape(7948748, 84)\n",
      "Thursday-22-02-2018\n",
      "DF:Thursday-22-02-2018, Shape(1048575, 80)\n",
      "Friday-16-02-2018\n",
      "DF:Friday-16-02-2018, Shape(1048574, 80)\n",
      "Wednesday-28-02-2018\n",
      "DF:Wednesday-28-02-2018, Shape(613071, 80)\n",
      "Wednesday-14-02-2018\n",
      "DF:Wednesday-14-02-2018, Shape(1048575, 80)\n",
      "Thursday-15-02-2018\n",
      "DF:Thursday-15-02-2018, Shape(1048575, 80)\n",
      "Thursday-01-03-2018\n",
      "DF:Thursday-01-03-2018, Shape(331100, 80)\n",
      "Friday-02-03-2018\n",
      "DF:Friday-02-03-2018, Shape(1048575, 80)\n"
     ]
    }
   ],
   "source": [
    "for k,df in dfs_parquet.items():\n",
    "    print(k)\n",
    "    df['is_allowed'] = df['Label'] == 'Benign'\n",
    "    del df['Label']\n",
    "    print(f'DF:{k}, Shape{df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3a9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cat_cols = ['Dst Port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7218f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([dfs_parquet['Friday-02-03-2018'], \n",
    "                      dfs_parquet['Friday-16-02-2018'], \n",
    "                      dfs_parquet['Friday-23-02-2018'],\n",
    "                      dfs_parquet['Thursday-01-03-2018'],\n",
    "                      dfs_parquet['Thursday-15-02-2018'],\n",
    "                      dfs_parquet['Thursday-22-02-2018'],\n",
    "                      dfs_parquet['Thuesday-20-02-2018'],\n",
    "                      dfs_parquet['Wednesday-14-02-2018'],\n",
    "                      dfs_parquet['Wednesday-21-02-2018']\n",
    "                     ]\n",
    "                    )\n",
    "#Transforming timestamp and category columns and also scaling data using minmax scalar\n",
    "df_train['Timestamp'] = pd.to_datetime(df_train['Timestamp'])\n",
    "df_train['Date'] = pd.to_datetime(df_train['Timestamp']).dt.date\n",
    "df_train['TS_relative'] = (df_train['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_train['Date']).astype(int))/ 10**9\n",
    "df_train = df_train.drop(['Timestamp'], axis = 1)\n",
    "df_train = df_train.drop(['Date'], axis = 1)\n",
    "df_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train[cat_cols] = df_train[cat_cols].astype('category')\n",
    "X_train = df_train.drop(['is_allowed'], axis = 1)\n",
    "y_train = df_train['is_allowed']*1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c842af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_scaled = stdsc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c23d0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43bb0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.concat([dfs_parquet['Wednesday-14-02-2018'],\n",
    "#                     dfs_parquet['Wednesday-21-02-2018'],\n",
    "#                     dfs_parquet['Wednesday-28-02-2018']]\n",
    "#                      )\n",
    "df_test = dfs_parquet['Wednesday-28-02-2018']\n",
    "#Transforming timestamp and category columns and also scaling data using minmax scalar\n",
    "df_test['Timestamp'] = pd.to_datetime(df_test['Timestamp'])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Timestamp']).dt.date\n",
    "df_test['TS_relative'] = (df_test['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_test['Date']).astype(int))/ 10**9\n",
    "df_test = df_test.drop(['Timestamp'], axis = 1)\n",
    "df_test = df_test.drop(['Date'], axis = 1)\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test[cat_cols] = df_test[cat_cols].astype('category')\n",
    "X_test = df_test.drop(['is_allowed'], axis = 1)\n",
    "y_test = df_test['is_allowed'].astype(int)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd68c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_test)\n",
    "X_test_scaled = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "861ab6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=79, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=2),\n",
    ")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "kl_weight = 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0e6920a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872, 79])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn =  torch.from_numpy(X_train_scaled).float()\n",
    "x_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb1b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn = torch.from_numpy(y_train.to_numpy())\n",
    "y_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7002be63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071, 79])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn_test =  torch.from_numpy(X_test_scaled).float()\n",
    "x_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d78f85e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn_test = torch.from_numpy(y_test.to_numpy())\n",
    "y_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d8a8a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100.............\n",
      "Epoch: 10/100.............\n",
      "Epoch: 20/100.............\n",
      "Epoch: 30/100.............\n",
      "Epoch: 40/100.............\n",
      "Epoch: 50/100.............\n",
      "Epoch: 60/100.............\n",
      "Epoch: 70/100.............\n",
      "Epoch: 80/100.............\n",
      "Epoch: 90/100.............\n",
      "F1: 0.9277979108427403\n",
      "Accuracy: 0.8867356915600845\n",
      "Precision: 0.9830814546721328\n",
      "Recall: 0.878401064316795\n"
     ]
    }
   ],
   "source": [
    "kl_weight = 0.1\n",
    "for step in range(100):\n",
    "    pre = model(x_for_nn)\n",
    "    ce = ce_loss(pre, y_for_nn)\n",
    "    kl = kl_loss(model)\n",
    "    cost = ce + kl_weight*kl\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print(f'Epoch: {step}/100.............')\n",
    "\n",
    "    \n",
    "_, predicted = torch.max(pre.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn, predicted)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn, predicted)}')\n",
    "print(f'Precision: {precision_score(y_for_nn, predicted)}')\n",
    "print(f'Recall: {recall_score(y_for_nn, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9dd44a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations):\n",
    "    pre_test = model(x_for_nn_test)\n",
    "    \n",
    "\n",
    "_, predicted_test = torch.max(pre_test.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c54d0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8626468822694336\n",
      "Accuracy: 0.7637484076069493\n",
      "Precision: 0.8912994487567142\n",
      "Recall: 0.835779125321573\n"
     ]
    }
   ],
   "source": [
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db6f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
