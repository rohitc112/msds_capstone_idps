{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808a05a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.10)\n",
      "Requirement already satisfied: awscli in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.24.10)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (8.0.0)\n",
      "Requirement already satisfied: torchbnn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.10 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.16)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (1.26.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (9.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (1.22.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (2.27.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.24.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (62.3.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.19.4)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 6)) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.9/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.0.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.2.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f6bb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "import socket\n",
    "from botocore.handlers import disable_signing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6861aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if socket.gethostname() == 'Rohits-MBP':\n",
    "    rootdir = '/Users/rohitchanne/Documents/capstone/data/data_parquet/'\n",
    "else: \n",
    "    rootdir = '' # Enter your hone dir here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb3cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = filter( os.path.isfile, glob.glob(rootdir + '*') )\n",
    "files_with_size = [ file_path for file_path in list_of_files ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e09aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data File: Wednesday-21-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-23-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thuesday-20-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-22-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-16-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-28-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-14-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-15-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-01-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-02-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "dfs_parquet = {}\n",
    "for file_path in files_with_size:\n",
    "    if 'parquet' in file_path:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        df_name = file_name.split('_')[0]\n",
    "        print(f'Reading Data File: {file_name}')       \n",
    "        dfs_parquet[df_name] = pd.read_parquet(file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d55ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_parquet['Thuesday-20-02-2018'].drop(['Flow ID', 'Src IP', 'Src Port', 'Dst IP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efcd1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wednesday-21-02-2018\n",
      "DF:Wednesday-21-02-2018, Shape(1048575, 80)\n",
      "Friday-23-02-2018\n",
      "DF:Friday-23-02-2018, Shape(1048575, 80)\n",
      "Thuesday-20-02-2018\n",
      "DF:Thuesday-20-02-2018, Shape(7948748, 84)\n",
      "Thursday-22-02-2018\n",
      "DF:Thursday-22-02-2018, Shape(1048575, 80)\n",
      "Friday-16-02-2018\n",
      "DF:Friday-16-02-2018, Shape(1048574, 80)\n",
      "Wednesday-28-02-2018\n",
      "DF:Wednesday-28-02-2018, Shape(613071, 80)\n",
      "Wednesday-14-02-2018\n",
      "DF:Wednesday-14-02-2018, Shape(1048575, 80)\n",
      "Thursday-15-02-2018\n",
      "DF:Thursday-15-02-2018, Shape(1048575, 80)\n",
      "Thursday-01-03-2018\n",
      "DF:Thursday-01-03-2018, Shape(331100, 80)\n",
      "Friday-02-03-2018\n",
      "DF:Friday-02-03-2018, Shape(1048575, 80)\n"
     ]
    }
   ],
   "source": [
    "for k,df in dfs_parquet.items():\n",
    "    print(k)\n",
    "    df['is_allowed'] = df['Label'] == 'Benign'\n",
    "    del df['Label']\n",
    "    print(f'DF:{k}, Shape{df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a984c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Dst Port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d3215e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([dfs_parquet['Friday-02-03-2018'], \n",
    "                      dfs_parquet['Friday-16-02-2018'], \n",
    "                      dfs_parquet['Friday-23-02-2018'],\n",
    "                      dfs_parquet['Thursday-01-03-2018'],\n",
    "                      dfs_parquet['Thursday-15-02-2018'],\n",
    "                      dfs_parquet['Thursday-22-02-2018'],\n",
    "#                       dfs_parquet['Thuesday-20-02-2018'],\n",
    "                      dfs_parquet['Wednesday-14-02-2018'],\n",
    "                      dfs_parquet['Wednesday-21-02-2018']\n",
    "                     ]\n",
    "                    )\n",
    "#Transforming timestamp and category columns and also scaling data using minmax scalar\n",
    "df_train['Timestamp'] = pd.to_datetime(df_train['Timestamp'])\n",
    "df_train['Date'] = pd.to_datetime(df_train['Timestamp']).dt.date\n",
    "df_train['TS_relative'] = (df_train['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_train['Date']).astype(int))/ 10**9\n",
    "df_train = df_train.drop(['Timestamp'], axis = 1)\n",
    "df_train = df_train.drop(['Date'], axis = 1)\n",
    "df_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train[cat_cols] = df_train[cat_cols].astype('category')\n",
    "X_train = df_train.drop(['is_allowed'], axis = 1)\n",
    "y_train = df_train['is_allowed']*1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c828db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(df_list):\n",
    "    df_temp = pd.concat(df_list)\n",
    "    df_temp['Timestamp'] = pd.to_datetime(df_temp['Timestamp'])\n",
    "    df_temp['Date'] = pd.to_datetime(df_temp['Timestamp']).dt.date\n",
    "    df_temp['TS_relative'] = (df_temp['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_temp['Date']).astype(int))/ 10**9\n",
    "    df_temp = df_temp.drop(['Timestamp'], axis = 1)\n",
    "    df_temp = df_temp.drop(['Date'], axis = 1)\n",
    "    df_temp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_temp.fillna(0, inplace=True)\n",
    "    df_temp[cat_cols] = df_temp[cat_cols].astype('category')\n",
    "    X_temp = df_temp.drop(['is_allowed'], axis = 1)\n",
    "    y_temp = df_temp['is_allowed']*1 \n",
    "    \n",
    "    return X_temp, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a91d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df):\n",
    "    stdsc = MinMaxScaler()\n",
    "    stdsc.fit(df)\n",
    "    return stdsc.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2681aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = transformations([dfs_parquet['Friday-02-03-2018'], \n",
    "                      dfs_parquet['Friday-16-02-2018'], \n",
    "                      dfs_parquet['Friday-23-02-2018'],\n",
    "                      dfs_parquet['Thursday-01-03-2018'],\n",
    "                      dfs_parquet['Thursday-15-02-2018'],\n",
    "                      dfs_parquet['Thursday-22-02-2018'],\n",
    "                      dfs_parquet['Thuesday-20-02-2018'],\n",
    "                      dfs_parquet['Wednesday-14-02-2018'],\n",
    "                      dfs_parquet['Wednesday-21-02-2018']\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3094035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scale_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d90d9c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15619872, 79)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0bf125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_scaled = stdsc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "95fc8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.concat([dfs_parquet['Wednesday-14-02-2018'],\n",
    "#                     dfs_parquet['Wednesday-21-02-2018'],\n",
    "#                     dfs_parquet['Wednesday-28-02-2018']]\n",
    "#                      )\n",
    "df_test = dfs_parquet['Wednesday-28-02-2018']\n",
    "#Transforming timestamp and category columns and also scaling data using minmax scalar\n",
    "df_test['Timestamp'] = pd.to_datetime(df_test['Timestamp'])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Timestamp']).dt.date\n",
    "df_test['TS_relative'] = (df_test['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_test['Date']).astype(int))/ 10**9\n",
    "df_test = df_test.drop(['Timestamp'], axis = 1)\n",
    "df_test = df_test.drop(['Date'], axis = 1)\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test[cat_cols] = df_test[cat_cols].astype('category')\n",
    "X_test = df_test.drop(['is_allowed'], axis = 1)\n",
    "y_test = df_test['is_allowed'].astype(int)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1f0ff4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_test)\n",
    "X_test_scaled = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf93a5",
   "metadata": {},
   "source": [
    "### Model Training Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "473c28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=79, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=2),\n",
    ")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6f970abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872, 79])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn =  torch.from_numpy(X_train_scaled).float()\n",
    "x_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7a76a00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn = torch.from_numpy(y_train.to_numpy())\n",
    "y_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cff1e2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071, 79])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn_test =  torch.from_numpy(X_test_scaled).float()\n",
    "x_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "323341ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn_test = torch.from_numpy(y_test.to_numpy())\n",
    "y_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b2157fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100.............\n",
      "F1: 0.8196092055961323\n",
      "Accuracy: 0.7011711712651236\n",
      "Precision: 0.7293915168505806\n",
      "Recall: 0.9352948687946427\n",
      "Epoch: 10/100.............\n",
      "F1: 0.9036414262357573\n",
      "Accuracy: 0.8502000489106942\n",
      "Precision: 0.8475196263525633\n",
      "Recall: 0.9677229558952656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m cost \u001b[38;5;241m=\u001b[39m ce \u001b[38;5;241m+\u001b[39m kl_weight\u001b[38;5;241m*\u001b[39mkl\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kl_weight = 0.1\n",
    "for step in range(100):\n",
    "    pre = model(x_for_nn)\n",
    "    ce = ce_loss(pre, y_for_nn)\n",
    "    kl = kl_loss(model)\n",
    "    cost = ce + kl_weight*kl\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print(f'Epoch: {step}/100.............')\n",
    "        _, predicted = torch.max(pre.data, 1)\n",
    "        print(f'F1: {f1_score(y_for_nn, predicted)}')\n",
    "        print(f'Accuracy: {accuracy_score(y_for_nn, predicted)}')\n",
    "        print(f'Precision: {precision_score(y_for_nn, predicted)}')\n",
    "        print(f'Recall: {recall_score(y_for_nn, predicted)}')\n",
    "\n",
    "print('Final--------------------------')    \n",
    "_, predicted = torch.max(pre.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn, predicted)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn, predicted)}')\n",
    "print(f'Precision: {precision_score(y_for_nn, predicted)}')\n",
    "print(f'Recall: {recall_score(y_for_nn, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b9484",
   "metadata": {},
   "source": [
    "### Model Testing Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1769213",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations):\n",
    "    pre_test = model(x_for_nn_test)\n",
    "    \n",
    "_, predicted_test = torch.max(pre_test.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e6664",
   "metadata": {},
   "source": [
    "### Trying out training with batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad60db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c8ab497",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_train)\n",
    "X_train_scaled = stdsc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fb64c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_test)\n",
    "X_test_scaled = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81d3a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=79, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=2),\n",
    ")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "kl_weight = 0.01\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b8d1863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6136899, 79])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn =  torch.from_numpy(X_train_scaled).float()\n",
    "x_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e0f7bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6136899])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn = torch.from_numpy(y_train.to_numpy())\n",
    "y_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6e02eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1534225, 79])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn_test =  torch.from_numpy(X_test_scaled).float()\n",
    "x_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0324c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1534225])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn_test = torch.from_numpy(y_test.to_numpy())\n",
    "y_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd53eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100.............\n",
      "F1: 0.8410199569940885\n",
      "Accuracy: 0.7256552535735068\n",
      "Precision: 0.7256552535735068\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "kl_weight = 0.1\n",
    "for step in range(10):\n",
    "    pre = model(x_for_nn)\n",
    "    ce = ce_loss(pre, y_for_nn)\n",
    "    kl = kl_loss(model)\n",
    "    cost = ce + kl_weight*kl\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print(f'Epoch: {step}/100.............')\n",
    "\n",
    "    \n",
    "_, predicted = torch.max(pre.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn, predicted)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn, predicted)}')\n",
    "print(f'Precision: {precision_score(y_for_nn, predicted)}')\n",
    "print(f'Recall: {recall_score(y_for_nn, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18649f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8416148118674033\n",
      "Accuracy: 0.7265414134171976\n",
      "Precision: 0.7265414134171976\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "pre_test = model(x_for_nn_test)\n",
    "_, predicted_test = torch.max(pre_test.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ed66079",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1048576\n",
    "train_data = TensorDataset(x_for_nn, y_for_nn)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b316cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 1...... Average Loss for Epoch: 0.45301762223243713\n",
      "F1: 0.9067402890959289\n",
      "Accuracy: 0.8293914794921875\n",
      "Precision: 0.8293914794921875\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 2...... Average Loss for Epoch: 0.46526767313480377\n",
      "F1: 0.9059732037637637\n",
      "Accuracy: 0.8281087875366211\n",
      "Precision: 0.8281087875366211\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 3...... Average Loss for Epoch: 0.4530884524186452\n",
      "F1: 0.906014865017131\n",
      "Accuracy: 0.8281784057617188\n",
      "Precision: 0.8281784057617188\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 4...... Average Loss for Epoch: 0.4430006369948387\n",
      "F1: 0.9059572232629743\n",
      "Accuracy: 0.8280820846557617\n",
      "Precision: 0.8280820846557617\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 5...... Average Loss for Epoch: 0.4351014494895935\n",
      "F1: 0.9061335536555546\n",
      "Accuracy: 0.8283767700195312\n",
      "Precision: 0.8283767700195312\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 6...... Average Loss for Epoch: 0.4339878062407176\n",
      "F1: 0.9063959467098306\n",
      "Accuracy: 0.8288154602050781\n",
      "Precision: 0.8288154602050781\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 7...... Average Loss for Epoch: 0.43247595855167936\n",
      "F1: 0.9059686379540332\n",
      "Accuracy: 0.8281011581420898\n",
      "Precision: 0.8281011581420898\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 8...... Average Loss for Epoch: 0.42786936089396477\n",
      "F1: 0.906252786975703\n",
      "Accuracy: 0.8285760879516602\n",
      "Precision: 0.8285760879516602\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 9...... Average Loss for Epoch: 0.42262399196624756\n",
      "F1: 0.9062094324123453\n",
      "Accuracy: 0.8285036087036133\n",
      "Precision: 0.8285036087036133\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 10...... Average Loss for Epoch: 0.41843381524086\n",
      "F1: 0.9061500995451228\n",
      "Accuracy: 0.828404426574707\n",
      "Precision: 0.828404426574707\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 11...... Average Loss for Epoch: 0.416457016359676\n",
      "F1: 0.9060747831738641\n",
      "Accuracy: 0.8282785415649414\n",
      "Precision: 0.8282785415649414\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 12...... Average Loss for Epoch: 0.41112961371739704\n",
      "F1: 0.9061278480603302\n",
      "Accuracy: 0.8283672332763672\n",
      "Precision: 0.8283672332763672\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 13...... Average Loss for Epoch: 0.4077141468341534\n",
      "F1: 0.9064563933509859\n",
      "Accuracy: 0.8289165496826172\n",
      "Precision: 0.8289165496826172\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 14...... Average Loss for Epoch: 0.40476704069546293\n",
      "F1: 0.906006875433627\n",
      "Accuracy: 0.8281650543212891\n",
      "Precision: 0.8281650543212891\n",
      "Recall: 1.0\n",
      "Epoch 0, Batch 15...... Average Loss for Epoch: 0.3994974732398987\n",
      "F1: 0.90634351436852\n",
      "Accuracy: 0.8287277826960401\n",
      "Precision: 0.8287277826960401\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 1...... Average Loss for Epoch: 0.38387495279312134\n",
      "F1: 0.9058379254896763\n",
      "Accuracy: 0.8278827667236328\n",
      "Precision: 0.8278827667236328\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 2...... Average Loss for Epoch: 0.36839523911476135\n",
      "F1: 0.9065715656218065\n",
      "Accuracy: 0.8291091918945312\n",
      "Precision: 0.8291091918945312\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 3...... Average Loss for Epoch: 0.34118356307347614\n",
      "F1: 0.9058955248019817\n",
      "Accuracy: 0.8279819488525391\n",
      "Precision: 0.8279789959162964\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 4...... Average Loss for Epoch: 0.3304390460252762\n",
      "F1: 0.9064415674348658\n",
      "Accuracy: 0.8288917541503906\n",
      "Precision: 0.8288917541503906\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 5...... Average Loss for Epoch: 0.3254575729370117\n",
      "F1: 0.9062647659200739\n",
      "Accuracy: 0.8285961151123047\n",
      "Precision: 0.8285961151123047\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 6...... Average Loss for Epoch: 0.3244168311357498\n",
      "F1: 0.9060770656405297\n",
      "Accuracy: 0.828282356262207\n",
      "Precision: 0.828282356262207\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 7...... Average Loss for Epoch: 0.3182179629802704\n",
      "F1: 0.9062881526266738\n",
      "Accuracy: 0.8286352157592773\n",
      "Precision: 0.8286352157592773\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 8...... Average Loss for Epoch: 0.3129802532494068\n",
      "F1: 0.9064518315734584\n",
      "Accuracy: 0.8289089202880859\n",
      "Precision: 0.8289089202880859\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 9...... Average Loss for Epoch: 0.30819430616166854\n",
      "F1: 0.9061985932344654\n",
      "Accuracy: 0.8284854888916016\n",
      "Precision: 0.8284854888916016\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 10...... Average Loss for Epoch: 0.3037785589694977\n",
      "F1: 0.9061016015556539\n",
      "Accuracy: 0.8283233642578125\n",
      "Precision: 0.8283233642578125\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 11...... Average Loss for Epoch: 0.3004604605111209\n",
      "F1: 0.9060468221842006\n",
      "Accuracy: 0.8282318115234375\n",
      "Precision: 0.8282318115234375\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 12...... Average Loss for Epoch: 0.29687778900067013\n",
      "F1: 0.9135344829399307\n",
      "Accuracy: 0.8431720733642578\n",
      "Precision: 0.8408331760481245\n",
      "Recall: 0.9999976977436736\n",
      "Epoch 1, Batch 13...... Average Loss for Epoch: 0.29399452071923476\n",
      "F1: 0.9066433934661949\n",
      "Accuracy: 0.8292293548583984\n",
      "Precision: 0.8292293548583984\n",
      "Recall: 1.0\n",
      "Epoch 1, Batch 14...... Average Loss for Epoch: 0.29168334177562166\n",
      "F1: 0.9331707708127992\n",
      "Accuracy: 0.8894929885864258\n",
      "Precision: 0.9343924510432368\n",
      "Recall: 0.9319522810057115\n",
      "Epoch 1, Batch 15...... Average Loss for Epoch: 0.2886078079541524\n",
      "F1: 0.9498192757310389\n",
      "Accuracy: 0.9135961813476795\n",
      "Precision: 0.9148770011714175\n",
      "Recall: 0.9875366710228565\n",
      "Epoch 2, Batch 1...... Average Loss for Epoch: 0.24534562230110168\n",
      "F1: 0.9495616151732295\n",
      "Accuracy: 0.9132843017578125\n",
      "Precision: 0.9168525195654363\n",
      "Recall: 0.9846908722762937\n",
      "Epoch 2, Batch 2...... Average Loss for Epoch: 0.25183162093162537\n",
      "F1: 0.9061554133243759\n",
      "Accuracy: 0.8284139633178711\n",
      "Precision: 0.8284148888486224\n",
      "Recall: 0.9999976975846512\n",
      "Epoch 2, Batch 3...... Average Loss for Epoch: 0.24970043202241263\n",
      "F1: 0.9369729091969168\n",
      "Accuracy: 0.8952579498291016\n",
      "Precision: 0.9341157516903006\n",
      "Recall: 0.9398475985664733\n",
      "Epoch 2, Batch 4...... Average Loss for Epoch: 0.25025054439902306\n",
      "F1: 0.9063504041327456\n",
      "Accuracy: 0.828740119934082\n",
      "Precision: 0.8287393032994428\n",
      "Recall: 1.0\n",
      "Epoch 2, Batch 5...... Average Loss for Epoch: 0.24735532104969024\n",
      "F1: 0.9426576795375764\n",
      "Accuracy: 0.9041910171508789\n",
      "Precision: 0.9351587396859408\n",
      "Recall: 0.9502778580133469\n",
      "Epoch 2, Batch 6...... Average Loss for Epoch: 0.24601593365271887\n",
      "F1: 0.9564499832541069\n",
      "Accuracy: 0.9262151718139648\n",
      "Precision: 0.9362288049209719\n",
      "Recall: 0.9775639402963092\n",
      "Epoch 2, Batch 7...... Average Loss for Epoch: 0.2445369873728071\n",
      "F1: 0.9572033872102064\n",
      "Accuracy: 0.9273996353149414\n",
      "Precision: 0.9349744659820988\n",
      "Recall: 0.9805150306532958\n",
      "Epoch 2, Batch 8...... Average Loss for Epoch: 0.24344086274504662\n",
      "F1: 0.9373273044059272\n",
      "Accuracy: 0.8969497680664062\n",
      "Precision: 0.9445334773445363\n",
      "Recall: 0.9302302556976801\n",
      "Epoch 2, Batch 9...... Average Loss for Epoch: 0.24334009322855207\n",
      "F1: 0.9422575993641842\n",
      "Accuracy: 0.900364875793457\n",
      "Precision: 0.9058485100305411\n",
      "Recall: 0.9817160599468158\n",
      "Epoch 2, Batch 10...... Average Loss for Epoch: 0.24305347949266434\n",
      "F1: 0.9607904714402391\n",
      "Accuracy: 0.933201789855957\n",
      "Precision: 0.9351749134205267\n",
      "Recall: 0.9878488309852508\n",
      "Epoch 2, Batch 11...... Average Loss for Epoch: 0.24236779727719046\n",
      "F1: 0.9305714538893023\n",
      "Accuracy: 0.8909072875976562\n",
      "Precision: 0.9831321623867612\n",
      "Recall: 0.8833455857782531\n",
      "Epoch 2, Batch 12...... Average Loss for Epoch: 0.2411891184747219\n",
      "F1: 0.9284753232883265\n",
      "Accuracy: 0.8861856460571289\n",
      "Precision: 0.968528727382758\n",
      "Recall: 0.8916031676603974\n",
      "Epoch 2, Batch 13...... Average Loss for Epoch: 0.24013817081084618\n",
      "F1: 0.9522121491558984\n",
      "Accuracy: 0.9200849533081055\n",
      "Precision: 0.9434215135660448\n",
      "Recall: 0.9611681447309494\n",
      "Epoch 2, Batch 14...... Average Loss for Epoch: 0.23879934740918024\n",
      "F1: 0.938445485620983\n",
      "Accuracy: 0.8989019393920898\n",
      "Precision: 0.9471353659994515\n",
      "Recall: 0.9299136132492672\n",
      "Epoch 2, Batch 15...... Average Loss for Epoch: 0.23752885758876802\n",
      "F1: 0.9372977785786402\n",
      "Accuracy: 0.8992900677585209\n",
      "Precision: 0.9681625771027302\n",
      "Recall: 0.9083401065481258\n",
      "Epoch 3, Batch 1...... Average Loss for Epoch: 0.21955135464668274\n",
      "F1: 0.9476074185619138\n",
      "Accuracy: 0.9123697280883789\n",
      "Precision: 0.9387196950783485\n",
      "Recall: 0.9566650472135813\n",
      "Epoch 3, Batch 2...... Average Loss for Epoch: 0.22296520322561264\n",
      "F1: 0.9563964162857599\n",
      "Accuracy: 0.9261646270751953\n",
      "Precision: 0.936069092564766\n",
      "Recall: 0.9776261780164994\n",
      "Epoch 3, Batch 3...... Average Loss for Epoch: 0.22520404557387033\n",
      "F1: 0.930469969313301\n",
      "Accuracy: 0.8906831741333008\n",
      "Precision: 0.9836937074435135\n",
      "Recall: 0.8827100534239922\n",
      "Epoch 3, Batch 4...... Average Loss for Epoch: 0.22260455042123795\n",
      "F1: 0.934984821265599\n",
      "Accuracy: 0.8967342376708984\n",
      "Precision: 0.9773966902206729\n",
      "Recall: 0.8961006077946412\n",
      "Epoch 3, Batch 5...... Average Loss for Epoch: 0.22084783315658568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9365044048851455\n",
      "Accuracy: 0.8949451446533203\n",
      "Precision: 0.9379782307238451\n",
      "Recall: 0.935035203364606\n",
      "Epoch 3, Batch 6...... Average Loss for Epoch: 0.21851693342129389\n",
      "F1: 0.9402030588066347\n",
      "Accuracy: 0.9007234573364258\n",
      "Precision: 0.9378644248047233\n",
      "Recall: 0.9425533850762496\n",
      "Epoch 3, Batch 7...... Average Loss for Epoch: 0.21839136736733572\n",
      "F1: 0.953747718052176\n",
      "Accuracy: 0.9204578399658203\n",
      "Precision: 0.920957992768896\n",
      "Recall: 0.9889585297973641\n",
      "Epoch 3, Batch 8...... Average Loss for Epoch: 0.22233273833990097\n",
      "F1: 0.9553650778930727\n",
      "Accuracy: 0.9228858947753906\n",
      "Precision: 0.9180976085367419\n",
      "Recall: 0.9957860821035068\n",
      "Epoch 3, Batch 9...... Average Loss for Epoch: 0.220656865172916\n",
      "F1: 0.9380622887564009\n",
      "Accuracy: 0.8982000350952148\n",
      "Precision: 0.9453948345611669\n",
      "Recall: 0.9308426109747167\n",
      "Epoch 3, Batch 10...... Average Loss for Epoch: 0.22127765268087388\n",
      "F1: 0.932748521980683\n",
      "Accuracy: 0.8947172164916992\n",
      "Precision: 0.9905266004313619\n",
      "Recall: 0.8813394055630895\n",
      "Epoch 3, Batch 11...... Average Loss for Epoch: 0.22904030707749454\n",
      "F1: 0.9269423559665797\n",
      "Accuracy: 0.8863973617553711\n",
      "Precision: 0.9919834602257811\n",
      "Recall: 0.8699055032364191\n",
      "Epoch 3, Batch 12...... Average Loss for Epoch: 0.22743629291653633\n",
      "F1: 0.9334218425585626\n",
      "Accuracy: 0.8951683044433594\n",
      "Precision: 0.9842633135943512\n",
      "Recall: 0.8875747551165212\n",
      "Epoch 3, Batch 13...... Average Loss for Epoch: 0.2254538364135302\n",
      "F1: 0.9429855998661573\n",
      "Accuracy: 0.9051008224487305\n",
      "Precision: 0.9388452437724897\n",
      "Recall: 0.9471626360902239\n",
      "Epoch 3, Batch 14...... Average Loss for Epoch: 0.22378178366592952\n",
      "F1: 0.9449864721770532\n",
      "Accuracy: 0.9082393646240234\n",
      "Precision: 0.9390023714103586\n",
      "Recall: 0.9510473334169619\n",
      "Epoch 3, Batch 15...... Average Loss for Epoch: 0.22346609930197397\n",
      "F1: 0.9549015015163096\n",
      "Accuracy: 0.9221479280874392\n",
      "Precision: 0.9177102412878797\n",
      "Recall: 0.9952345221545253\n",
      "Epoch 4, Batch 1...... Average Loss for Epoch: 0.2171170711517334\n",
      "F1: 0.9544899800130888\n",
      "Accuracy: 0.921478271484375\n",
      "Precision: 0.9179102335535023\n",
      "Recall: 0.9941062215687652\n",
      "Epoch 4, Batch 2...... Average Loss for Epoch: 0.21643472462892532\n",
      "F1: 0.9548118195612578\n",
      "Accuracy: 0.9220399856567383\n",
      "Precision: 0.9180006547702564\n",
      "Recall: 0.9946985132111024\n",
      "Epoch 4, Batch 3...... Average Loss for Epoch: 0.20933916171391806\n",
      "F1: 0.9366664017445412\n",
      "Accuracy: 0.8958845138549805\n",
      "Precision: 0.9438485730653666\n",
      "Recall: 0.9295927097450967\n",
      "Epoch 4, Batch 4...... Average Loss for Epoch: 0.20869148895144463\n",
      "F1: 0.9525765380417022\n",
      "Accuracy: 0.9186267852783203\n",
      "Precision: 0.9206946936407491\n",
      "Recall: 0.9867455951067745\n",
      "Epoch 4, Batch 5...... Average Loss for Epoch: 0.20891737937927246\n",
      "F1: 0.9331256292724687\n",
      "Accuracy: 0.8946599960327148\n",
      "Precision: 0.9850534117156812\n",
      "Recall: 0.8863985092996238\n",
      "Epoch 4, Batch 6...... Average Loss for Epoch: 0.20788824061552683\n",
      "F1: 0.9333379873811112\n",
      "Accuracy: 0.8943634033203125\n",
      "Precision: 0.9781299036797465\n",
      "Recall: 0.8924687868296994\n",
      "Epoch 4, Batch 7...... Average Loss for Epoch: 0.21024284831115178\n",
      "F1: 0.934225375210306\n",
      "Accuracy: 0.8967247009277344\n",
      "Precision: 0.9902068459374377\n",
      "Recall: 0.8842350344066364\n",
      "Epoch 4, Batch 8...... Average Loss for Epoch: 0.20875409431755543\n",
      "F1: 0.9437436447082749\n",
      "Accuracy: 0.9102001190185547\n",
      "Precision: 0.9805788720276413\n",
      "Recall: 0.909575638086047\n",
      "Epoch 4, Batch 9...... Average Loss for Epoch: 0.20687253110938603\n",
      "F1: 0.9396527901948991\n",
      "Accuracy: 0.9008655548095703\n",
      "Precision: 0.9471573260677729\n",
      "Recall: 0.9322662396756096\n",
      "Epoch 4, Batch 10...... Average Loss for Epoch: 0.20597495883703232\n",
      "F1: 0.9525774846008961\n",
      "Accuracy: 0.9186258316040039\n",
      "Precision: 0.9210335125282387\n",
      "Recall: 0.9863587447559088\n",
      "Epoch 4, Batch 11...... Average Loss for Epoch: 0.20604503425684842\n",
      "F1: 0.9566131977811094\n",
      "Accuracy: 0.9250965118408203\n",
      "Precision: 0.9205190574807469\n",
      "Recall: 0.9956534037987871\n",
      "Epoch 4, Batch 12...... Average Loss for Epoch: 0.20496862257520357\n",
      "F1: 0.9548751534453258\n",
      "Accuracy: 0.9223842620849609\n",
      "Precision: 0.9211541732500783\n",
      "Recall: 0.9911588155736526\n",
      "Epoch 4, Batch 13...... Average Loss for Epoch: 0.2037659757412397\n",
      "F1: 0.9481656609224272\n",
      "Accuracy: 0.9114303588867188\n",
      "Precision: 0.9204330950126023\n",
      "Recall: 0.9776213023472082\n",
      "Epoch 4, Batch 14...... Average Loss for Epoch: 0.2025475651025772\n",
      "F1: 0.9449729048020249\n",
      "Accuracy: 0.9098711013793945\n",
      "Precision: 0.9554882306327352\n",
      "Recall: 0.9346865058248155\n",
      "Epoch 4, Batch 15...... Average Loss for Epoch: 0.2023110737403234\n",
      "F1: 0.9361052606030532\n",
      "Accuracy: 0.8991581259150805\n",
      "Precision: 0.9844932109050945\n",
      "Recall: 0.8922510239989101\n",
      "Epoch 5, Batch 1...... Average Loss for Epoch: 0.18933477997779846\n",
      "F1: 0.9535019946753135\n",
      "Accuracy: 0.9201345443725586\n",
      "Precision: 0.9214119767997124\n",
      "Recall: 0.9879078650651203\n",
      "Epoch 5, Batch 2...... Average Loss for Epoch: 0.19371864199638367\n",
      "F1: 0.9351001408064634\n",
      "Accuracy: 0.8977136611938477\n",
      "Precision: 0.9850675104570772\n",
      "Recall: 0.8899572231193261\n",
      "Epoch 5, Batch 3...... Average Loss for Epoch: 0.19188603262106577\n",
      "F1: 0.9376993403360765\n",
      "Accuracy: 0.9009523391723633\n",
      "Precision: 0.9788819269020606\n",
      "Recall: 0.8998420443058814\n",
      "Epoch 5, Batch 4...... Average Loss for Epoch: 0.19032682478427887\n",
      "F1: 0.9621154574401101\n",
      "Accuracy: 0.9355049133300781\n",
      "Precision: 0.9372803436789187\n",
      "Recall: 0.9883025052249731\n",
      "Epoch 5, Batch 5...... Average Loss for Epoch: 0.18944135010242463\n",
      "F1: 0.9648734396994331\n",
      "Accuracy: 0.9406709671020508\n",
      "Precision: 0.9468800492932928\n",
      "Recall: 0.9835639272060863\n",
      "Epoch 5, Batch 6...... Average Loss for Epoch: 0.19050642599662146\n",
      "F1: 0.9567674246748706\n",
      "Accuracy: 0.9254608154296875\n",
      "Precision: 0.9207874200176733\n",
      "Recall: 0.995673627084614\n",
      "Epoch 5, Batch 7...... Average Loss for Epoch: 0.1889402504478182\n",
      "F1: 0.9475763297238436\n",
      "Accuracy: 0.9144191741943359\n",
      "Precision: 0.9633726828039884\n",
      "Recall: 0.932289643027108\n",
      "Epoch 5, Batch 8...... Average Loss for Epoch: 0.18872350826859474\n",
      "F1: 0.9500886723256253\n",
      "Accuracy: 0.9170646667480469\n",
      "Precision: 0.9473787223424676\n",
      "Recall: 0.9528141702534727\n",
      "Epoch 5, Batch 9...... Average Loss for Epoch: 0.1882905529605018\n",
      "F1: 0.9566704827706255\n",
      "Accuracy: 0.925933837890625\n",
      "Precision: 0.928452308758555\n",
      "Recall: 0.9866576751165756\n",
      "Epoch 5, Batch 10...... Average Loss for Epoch: 0.1884759247303009\n",
      "F1: 0.9372187563764653\n",
      "Accuracy: 0.9008216857910156\n",
      "Precision: 0.9850086986093646\n",
      "Recall: 0.8938515127961539\n",
      "Epoch 5, Batch 11...... Average Loss for Epoch: 0.1875543323430148\n",
      "F1: 0.9486182192746598\n",
      "Accuracy: 0.9152746200561523\n",
      "Precision: 0.9534194020914591\n",
      "Recall: 0.9438651492970196\n",
      "Epoch 5, Batch 12...... Average Loss for Epoch: 0.18694951136906943\n",
      "F1: 0.9536408754185898\n",
      "Accuracy: 0.9231481552124023\n",
      "Precision: 0.9530635359592486\n",
      "Recall: 0.9542189147743757\n",
      "Epoch 5, Batch 13...... Average Loss for Epoch: 0.1865748235812554\n",
      "F1: 0.964466878614844\n",
      "Accuracy: 0.940150260925293\n",
      "Precision: 0.9491818771467228\n",
      "Recall: 0.9802522164176614\n",
      "Epoch 5, Batch 14...... Average Loss for Epoch: 0.18652231565543584\n",
      "F1: 0.9602943626770342\n",
      "Accuracy: 0.9318218231201172\n",
      "Precision: 0.9275356876545661\n",
      "Recall: 0.9954516929489726\n",
      "Epoch 5, Batch 15...... Average Loss for Epoch: 0.18589845299720764\n",
      "F1: 0.9502490281547024\n",
      "Accuracy: 0.9196144318839593\n",
      "Precision: 0.9736387534884725\n",
      "Recall: 0.9279567223286186\n",
      "Epoch 6, Batch 1...... Average Loss for Epoch: 0.18017548322677612\n",
      "F1: 0.9582816478422668\n",
      "Accuracy: 0.9287004470825195\n",
      "Precision: 0.9296400913331984\n",
      "Recall: 0.9887441590533809\n",
      "Epoch 6, Batch 2...... Average Loss for Epoch: 0.17747461050748825\n",
      "F1: 0.9470353956305583\n",
      "Accuracy: 0.9131631851196289\n",
      "Precision: 0.9570036326017187\n",
      "Recall: 0.9372726780781936\n",
      "Epoch 6, Batch 3...... Average Loss for Epoch: 0.17620902260144553\n",
      "F1: 0.9478894864263938\n",
      "Accuracy: 0.9144840240478516\n",
      "Precision: 0.9571519276292548\n",
      "Recall: 0.9388045939434264\n",
      "Epoch 6, Batch 4...... Average Loss for Epoch: 0.17553385719656944\n",
      "F1: 0.9525361838083577\n",
      "Accuracy: 0.921879768371582\n",
      "Precision: 0.9588392157228713\n",
      "Recall: 0.9463154780202004\n",
      "Epoch 6, Batch 5...... Average Loss for Epoch: 0.17474740445613862\n",
      "F1: 0.9522650126146254\n",
      "Accuracy: 0.9210214614868164\n",
      "Precision: 0.9535054720154401\n",
      "Recall: 0.9510277765625036\n",
      "Epoch 6, Batch 6...... Average Loss for Epoch: 0.17385627329349518\n",
      "F1: 0.9619617677999713\n",
      "Accuracy: 0.9364128112792969\n",
      "Precision: 0.9534620982598754\n",
      "Recall: 0.9706143415828077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 7...... Average Loss for Epoch: 0.17486406862735748\n",
      "F1: 0.9589414194097235\n",
      "Accuracy: 0.9296693801879883\n",
      "Precision: 0.9276751272972481\n",
      "Recall: 0.9923888168038332\n",
      "Epoch 6, Batch 8...... Average Loss for Epoch: 0.17381695471704006\n",
      "F1: 0.9659341477230439\n",
      "Accuracy: 0.9428186416625977\n",
      "Precision: 0.9539555782990834\n",
      "Recall: 0.9782173660377793\n",
      "Epoch 6, Batch 9...... Average Loss for Epoch: 0.17295365863376194\n",
      "F1: 0.9680173455242271\n",
      "Accuracy: 0.9462480545043945\n",
      "Precision: 0.9545983597750958\n",
      "Recall: 0.9818189770973211\n",
      "Epoch 6, Batch 10...... Average Loss for Epoch: 0.172318759560585\n",
      "F1: 0.9489254572279404\n",
      "Accuracy: 0.9157800674438477\n",
      "Precision: 0.9537015185985601\n",
      "Recall: 0.9441969937619409\n",
      "Epoch 6, Batch 11...... Average Loss for Epoch: 0.1720787544142116\n",
      "F1: 0.9587299462630962\n",
      "Accuracy: 0.9294309616088867\n",
      "Precision: 0.9301393641497142\n",
      "Recall: 0.9891338997699498\n",
      "Epoch 6, Batch 12...... Average Loss for Epoch: 0.17163229609529176\n",
      "F1: 0.9586533134645779\n",
      "Accuracy: 0.9293222427368164\n",
      "Precision: 0.930135802843372\n",
      "Recall: 0.9889747990473526\n",
      "Epoch 6, Batch 13...... Average Loss for Epoch: 0.17249968418708214\n",
      "F1: 0.9408025278894506\n",
      "Accuracy: 0.9061660766601562\n",
      "Precision: 0.9862230771656523\n",
      "Recall: 0.8993814727092232\n",
      "Epoch 6, Batch 14...... Average Loss for Epoch: 0.1721967054264886\n",
      "F1: 0.9498612496577805\n",
      "Accuracy: 0.9191350936889648\n",
      "Precision: 0.9770905538679763\n",
      "Recall: 0.924108437228182\n",
      "Epoch 6, Batch 15...... Average Loss for Epoch: 0.1715812623500824\n",
      "F1: 0.9709141781386639\n",
      "Accuracy: 0.9509772208791583\n",
      "Precision: 0.9546016001787632\n",
      "Recall: 0.9877939591530533\n",
      "Epoch 7, Batch 1...... Average Loss for Epoch: 0.1646541953086853\n",
      "F1: 0.969823026608934\n",
      "Accuracy: 0.9492340087890625\n",
      "Precision: 0.9550841439558378\n",
      "Recall: 0.9850239409663445\n",
      "Epoch 7, Batch 2...... Average Loss for Epoch: 0.1658572405576706\n",
      "F1: 0.9708410760297432\n",
      "Accuracy: 0.950840950012207\n",
      "Precision: 0.9550671344112829\n",
      "Recall: 0.987144814384924\n",
      "Epoch 7, Batch 3...... Average Loss for Epoch: 0.16476385295391083\n",
      "F1: 0.9692289015281734\n",
      "Accuracy: 0.9482707977294922\n",
      "Precision: 0.9553182519153713\n",
      "Recall: 0.9835506508010523\n",
      "Epoch 7, Batch 4...... Average Loss for Epoch: 0.17183513939380646\n",
      "F1: 0.9605528431856092\n",
      "Accuracy: 0.9321155548095703\n",
      "Precision: 0.9260301256249459\n",
      "Recall: 0.997749274990243\n",
      "Epoch 7, Batch 5...... Average Loss for Epoch: 0.17112936377525328\n",
      "F1: 0.9423101070531028\n",
      "Accuracy: 0.9075498580932617\n",
      "Precision: 0.9752528300957121\n",
      "Recall: 0.9115201866053553\n",
      "Epoch 7, Batch 6...... Average Loss for Epoch: 0.1757228970527649\n",
      "F1: 0.940193845786818\n",
      "Accuracy: 0.9058046340942383\n",
      "Precision: 0.992019115279446\n",
      "Recall: 0.8935146662615563\n",
      "Epoch 7, Batch 7...... Average Loss for Epoch: 0.17533755089555467\n",
      "F1: 0.942760013818782\n",
      "Accuracy: 0.9089851379394531\n",
      "Precision: 0.9842703102105224\n",
      "Recall: 0.904609314392396\n",
      "Epoch 7, Batch 8...... Average Loss for Epoch: 0.17367124371230602\n",
      "F1: 0.9711359677561469\n",
      "Accuracy: 0.951263427734375\n",
      "Precision: 0.9537842302567567\n",
      "Recall: 0.9891307474322585\n",
      "Epoch 7, Batch 9...... Average Loss for Epoch: 0.1750912302070194\n",
      "F1: 0.9580439790830516\n",
      "Accuracy: 0.9275922775268555\n",
      "Precision: 0.9215674601065243\n",
      "Recall: 0.9975270511148984\n",
      "Epoch 7, Batch 10...... Average Loss for Epoch: 0.17392507642507554\n",
      "F1: 0.9601907674093065\n",
      "Accuracy: 0.9317626953125\n",
      "Precision: 0.9293491723298618\n",
      "Recall: 0.9931496601301473\n",
      "Epoch 7, Batch 11...... Average Loss for Epoch: 0.17266113649715076\n",
      "F1: 0.9713695727810951\n",
      "Accuracy: 0.9517374038696289\n",
      "Precision: 0.9547871482638545\n",
      "Recall: 0.988538173845757\n",
      "Epoch 7, Batch 12...... Average Loss for Epoch: 0.17231166983644167\n",
      "F1: 0.9442181598464847\n",
      "Accuracy: 0.9109001159667969\n",
      "Precision: 0.9809620220501121\n",
      "Recall: 0.9101275424172631\n",
      "Epoch 7, Batch 13...... Average Loss for Epoch: 0.18015518211401427\n",
      "F1: 0.9322991650529402\n",
      "Accuracy: 0.8942079544067383\n",
      "Precision: 0.9927603856621843\n",
      "Recall: 0.8787796159319994\n",
      "Epoch 7, Batch 14...... Average Loss for Epoch: 0.17887867987155914\n",
      "F1: 0.9620556277159392\n",
      "Accuracy: 0.9369535446166992\n",
      "Precision: 0.958976025484937\n",
      "Recall: 0.9651550729961893\n",
      "Epoch 7, Batch 15...... Average Loss for Epoch: 0.17789652645587922\n",
      "F1: 0.9716169884013917\n",
      "Accuracy: 0.9521519289046273\n",
      "Precision: 0.954099872568513\n",
      "Recall: 0.9897893572696176\n",
      "Epoch 8, Batch 1...... Average Loss for Epoch: 0.1703220009803772\n",
      "F1: 0.9605645948720232\n",
      "Accuracy: 0.9324026107788086\n",
      "Precision: 0.9297609405560965\n",
      "Recall: 0.9934792841252907\n",
      "Epoch 8, Batch 2...... Average Loss for Epoch: 0.18485818803310394\n",
      "F1: 0.9578707850503291\n",
      "Accuracy: 0.9271993637084961\n",
      "Precision: 0.9204844375806123\n",
      "Recall: 0.998422667567123\n",
      "Epoch 8, Batch 3...... Average Loss for Epoch: 0.17597247660160065\n",
      "F1: 0.9693934650498146\n",
      "Accuracy: 0.9485158920288086\n",
      "Precision: 0.9550208223487252\n",
      "Recall: 0.9842053216093534\n",
      "Epoch 8, Batch 4...... Average Loss for Epoch: 0.1726568415760994\n",
      "F1: 0.9419413295472989\n",
      "Accuracy: 0.9068708419799805\n",
      "Precision: 0.9748065545043759\n",
      "Recall: 0.9112199038579887\n",
      "Epoch 8, Batch 5...... Average Loss for Epoch: 0.17029713690280915\n",
      "F1: 0.9499865214244465\n",
      "Accuracy: 0.9191408157348633\n",
      "Precision: 0.9744400208139211\n",
      "Recall: 0.9267302940570575\n",
      "Epoch 8, Batch 6...... Average Loss for Epoch: 0.16756881028413773\n",
      "F1: 0.9699136474223348\n",
      "Accuracy: 0.9493350982666016\n",
      "Precision: 0.9549974238358749\n",
      "Recall: 0.9853032210258404\n",
      "Epoch 8, Batch 7...... Average Loss for Epoch: 0.1663116259234292\n",
      "F1: 0.9577637971924505\n",
      "Accuracy: 0.9305524826049805\n",
      "Precision: 0.9652325584114062\n",
      "Recall: 0.9504097318066761\n",
      "Epoch 8, Batch 8...... Average Loss for Epoch: 0.16535218246281147\n",
      "F1: 0.9719347751711346\n",
      "Accuracy: 0.9526700973510742\n",
      "Precision: 0.9551680406538675\n",
      "Recall: 0.9893006635568674\n",
      "Epoch 8, Batch 9...... Average Loss for Epoch: 0.16432628201113808\n",
      "F1: 0.9708361569830344\n",
      "Accuracy: 0.9508733749389648\n",
      "Precision: 0.955016456986283\n",
      "Recall: 0.9871887866478765\n",
      "Epoch 8, Batch 10...... Average Loss for Epoch: 0.16358995139598848\n",
      "F1: 0.9697662453179006\n",
      "Accuracy: 0.9491720199584961\n",
      "Precision: 0.9555978642435192\n",
      "Recall: 0.9843610906699741\n",
      "Epoch 8, Batch 11...... Average Loss for Epoch: 0.16270039569247852\n",
      "F1: 0.9688245752263227\n",
      "Accuracy: 0.9476242065429688\n",
      "Precision: 0.9554349359469573\n",
      "Recall: 0.9825948383263594\n",
      "Epoch 8, Batch 12...... Average Loss for Epoch: 0.1621931791305542\n",
      "F1: 0.9713949417377168\n",
      "Accuracy: 0.9528121948242188\n",
      "Precision: 0.9751959057980687\n",
      "Recall: 0.9676234922309511\n",
      "Epoch 8, Batch 13...... Average Loss for Epoch: 0.16200120403216436\n",
      "F1: 0.9704160400188778\n",
      "Accuracy: 0.9513378143310547\n",
      "Precision: 0.9776087322206232\n",
      "Recall: 0.9633284143205432\n",
      "Epoch 8, Batch 14...... Average Loss for Epoch: 0.16140585179839814\n",
      "F1: 0.9694961807801877\n",
      "Accuracy: 0.9487380981445312\n",
      "Precision: 0.9553866423885058\n",
      "Recall: 0.9840287169751329\n",
      "Epoch 8, Batch 15...... Average Loss for Epoch: 0.16082392235596973\n",
      "F1: 0.969926761703581\n",
      "Accuracy: 0.9494045592291191\n",
      "Precision: 0.9554530207614268\n",
      "Recall: 0.9848457604348351\n",
      "Epoch 9, Batch 1...... Average Loss for Epoch: 0.1581496000289917\n",
      "F1: 0.9641914990455465\n",
      "Accuracy: 0.9389247894287109\n",
      "Precision: 0.9374638478500071\n",
      "Recall: 0.9924879192019651\n",
      "Epoch 9, Batch 2...... Average Loss for Epoch: 0.15903303027153015\n",
      "F1: 0.9652350110562115\n",
      "Accuracy: 0.9408502578735352\n",
      "Precision: 0.9406909375761356\n",
      "Recall: 0.9910941827298281\n",
      "Epoch 9, Batch 3...... Average Loss for Epoch: 0.1642205367485682\n",
      "F1: 0.9448277558376081\n",
      "Accuracy: 0.9122934341430664\n",
      "Precision: 0.9869158175734105\n",
      "Recall: 0.9061826450494075\n",
      "Epoch 9, Batch 4...... Average Loss for Epoch: 0.16115454211831093\n",
      "F1: 0.9762742773566182\n",
      "Accuracy: 0.9606437683105469\n",
      "Precision: 0.9754812751896837\n",
      "Recall: 0.9770685698898252\n",
      "Epoch 9, Batch 5...... Average Loss for Epoch: 0.15944202542304992\n",
      "F1: 0.9686199922484168\n",
      "Accuracy: 0.9483442306518555\n",
      "Precision: 0.9747226711253827\n",
      "Recall: 0.9625932549026833\n",
      "Epoch 9, Batch 6...... Average Loss for Epoch: 0.158652496834596\n",
      "F1: 0.9713645533973653\n",
      "Accuracy: 0.9517841339111328\n",
      "Precision: 0.9555663028676751\n",
      "Recall: 0.9876939663115992\n",
      "Epoch 9, Batch 7...... Average Loss for Epoch: 0.16455242250646865\n",
      "F1: 0.9459762857325287\n",
      "Accuracy: 0.9055929183959961\n",
      "Precision: 0.8987869995219345\n",
      "Recall: 0.9983953387643763\n",
      "Epoch 9, Batch 8...... Average Loss for Epoch: 0.16259734705090523\n",
      "F1: 0.9684187819492106\n",
      "Accuracy: 0.9469442367553711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9553835642521925\n",
      "Recall: 0.981814624039596\n",
      "Epoch 9, Batch 9...... Average Loss for Epoch: 0.16352462602986229\n",
      "F1: 0.9624559446191118\n",
      "Accuracy: 0.9356222152709961\n",
      "Precision: 0.9313934550637087\n",
      "Recall: 0.9956618198723172\n",
      "Epoch 9, Batch 10...... Average Loss for Epoch: 0.1623132437467575\n",
      "F1: 0.9719616868345355\n",
      "Accuracy: 0.9537811279296875\n",
      "Precision: 0.9772218047124572\n",
      "Recall: 0.9667578933315533\n",
      "Epoch 9, Batch 11...... Average Loss for Epoch: 0.16347378221425143\n",
      "F1: 0.9444208135814514\n",
      "Accuracy: 0.9121484756469727\n",
      "Precision: 0.9922864608624102\n",
      "Recall: 0.9009605223473398\n",
      "Epoch 9, Batch 12...... Average Loss for Epoch: 0.16436213006575903\n",
      "F1: 0.9459572242031399\n",
      "Accuracy: 0.9142856597900391\n",
      "Precision: 0.9901215174195107\n",
      "Recall: 0.9055645863169383\n",
      "Epoch 9, Batch 13...... Average Loss for Epoch: 0.1630904651605166\n",
      "F1: 0.969807661775046\n",
      "Accuracy: 0.9492206573486328\n",
      "Precision: 0.9557197427741854\n",
      "Recall: 0.9843171244339777\n",
      "Epoch 9, Batch 14...... Average Loss for Epoch: 0.16195352694817952\n",
      "F1: 0.9686606001712051\n",
      "Accuracy: 0.9473142623901367\n",
      "Precision: 0.9551092734790313\n",
      "Recall: 0.9826020004764683\n",
      "Epoch 9, Batch 15...... Average Loss for Epoch: 0.16353054642677306\n",
      "F1: 0.9608975012748597\n",
      "Accuracy: 0.9326873148558004\n",
      "Precision: 0.926179198913296\n",
      "Recall: 0.9983200400724387\n"
     ]
    }
   ],
   "source": [
    "kl_weight = 0.1\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.process_time()\n",
    "    avg_loss = 0.\n",
    "    counter = 0\n",
    "    for x, y in train_loader:\n",
    "        counter += 1\n",
    "        pre = model(x)\n",
    "        ce = ce_loss(pre, y)\n",
    "        kl = kl_loss(model)\n",
    "        cost = ce + kl_weight*kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += cost.item()\n",
    "        if epoch%1 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {counter}...... Average Loss for Epoch: {avg_loss/counter}\")\n",
    "            _, predicted = torch.max(pre.data, 1)\n",
    "            print(f'F1: {f1_score(y, predicted)}')\n",
    "            print(f'Accuracy: {accuracy_score(y, predicted)}')\n",
    "            print(f'Precision: {precision_score(y, predicted)}')\n",
    "            print(f'Recall: {recall_score(y, predicted)}')            \n",
    "    current_time = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0239d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9198960533303966\n",
      "Accuracy: 0.8528816401362974\n",
      "Precision: 0.8901990848491308\n",
      "Recall: 0.9516427783902977\n"
     ]
    }
   ],
   "source": [
    "pre_test = model(x_for_nn_test)\n",
    "_, predicted_test = torch.max(pre_test.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7df7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dfs_parquet['Wednesday-28-02-2018']\n",
    "#Transforming timestamp and category columns and also scaling data using minmax scalar\n",
    "df_test['Timestamp'] = pd.to_datetime(df_test['Timestamp'])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Timestamp']).dt.date\n",
    "df_test['TS_relative'] = (df_test['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_test['Date']).astype(int))/ 10**9\n",
    "df_test = df_test.drop(['Timestamp'], axis = 1)\n",
    "df_test = df_test.drop(['Date'], axis = 1)\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test[cat_cols] = df_test[cat_cols].astype('category')\n",
    "X_test = df_test.drop(['is_allowed'], axis = 1)\n",
    "y_test = df_test['is_allowed'].astype(int)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a9389f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdsc = MinMaxScaler()\n",
    "stdsc.fit(X_test)\n",
    "X_test_scaled = stdsc.transform(X_test)\n",
    "x_for_nn_test =  torch.from_numpy(X_test_scaled).float()\n",
    "x_for_nn_test.shape\n",
    "y_for_nn_test = torch.from_numpy(y_test.to_numpy())\n",
    "y_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab1f2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7754044128302481\n",
      "Accuracy: 0.6460768817967251\n",
      "Precision: 0.8878006693656196\n",
      "Recall: 0.6882690187431092\n"
     ]
    }
   ],
   "source": [
    "pre_test = model(x_for_nn_test)\n",
    "_, predicted_test = torch.max(pre_test.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03977205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
