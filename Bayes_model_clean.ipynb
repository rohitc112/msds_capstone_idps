{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5ef3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.10)\n",
      "Requirement already satisfied: awscli in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.24.10)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (8.0.0)\n",
      "Requirement already satisfied: torchbnn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.10 in /usr/local/lib/python3.9/site-packages (from boto3->-r requirements.txt (line 1)) (1.26.10)\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.16)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (4.7.2)\n",
      "Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.9/site-packages (from awscli->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.10->boto3->-r requirements.txt (line 1)) (1.26.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (9.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 4)) (1.22.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.44.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (13.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.24.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (62.3.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (3.19.4)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.9/site-packages (from tensorflow->-r requirements.txt (line 5)) (2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 6)) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.37.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.9/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.3.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 4)) (2021.10.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r requirements.txt (line 5)) (3.2.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e649f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "import socket\n",
    "from botocore.handlers import disable_signing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchbnn as bnn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2b4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if socket.gethostname() == 'Rohits-MacBook-Pro.local':\n",
    "    rootdir = '/Users/rohitchanne/Documents/capstone/data/data_parquet/'\n",
    "else: \n",
    "    rootdir = '' # Enter your hone dir here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a25d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data File: Wednesday-21-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-23-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thuesday-20-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-22-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-16-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-28-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Wednesday-14-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-15-02-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Thursday-01-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n",
      "Reading Data File: Friday-02-03-2018_TrafficForML_CICFlowMeter_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "list_of_files = filter( os.path.isfile, glob.glob(rootdir + '*') )\n",
    "files_with_size = [ file_path for file_path in list_of_files ]\n",
    "\n",
    "dfs_parquet = {}\n",
    "for file_path in files_with_size:\n",
    "    if 'parquet' in file_path:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        df_name = file_name.split('_')[0]\n",
    "        print(f'Reading Data File: {file_name}')       \n",
    "        dfs_parquet[df_name] = pd.read_parquet(file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfe6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping extra data for Thuesday-20-02-2018 file\n",
    "dfs_parquet['Thuesday-20-02-2018'].drop(['Flow ID', 'Src IP', 'Src Port', 'Dst IP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef39c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wednesday-21-02-2018\n",
      "DF:Wednesday-21-02-2018, Shape(1048575, 80)\n",
      "Friday-23-02-2018\n",
      "DF:Friday-23-02-2018, Shape(1048575, 80)\n",
      "Thuesday-20-02-2018\n",
      "DF:Thuesday-20-02-2018, Shape(7948748, 80)\n",
      "Thursday-22-02-2018\n",
      "DF:Thursday-22-02-2018, Shape(1048575, 80)\n",
      "Friday-16-02-2018\n",
      "DF:Friday-16-02-2018, Shape(1048574, 80)\n",
      "Wednesday-28-02-2018\n",
      "DF:Wednesday-28-02-2018, Shape(613071, 80)\n",
      "Wednesday-14-02-2018\n",
      "DF:Wednesday-14-02-2018, Shape(1048575, 80)\n",
      "Thursday-15-02-2018\n",
      "DF:Thursday-15-02-2018, Shape(1048575, 80)\n",
      "Thursday-01-03-2018\n",
      "DF:Thursday-01-03-2018, Shape(331100, 80)\n",
      "Friday-02-03-2018\n",
      "DF:Friday-02-03-2018, Shape(1048575, 80)\n"
     ]
    }
   ],
   "source": [
    "for k,df in dfs_parquet.items():\n",
    "    print(k)\n",
    "    df['is_allowed'] = df['Label'] == 'Benign'\n",
    "    del df['Label']\n",
    "    print(f'DF:{k}, Shape{df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae81e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Dst Port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec32941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformations(df_list):\n",
    "    df_temp = pd.concat(df_list)\n",
    "    df_temp['Timestamp'] = pd.to_datetime(df_temp['Timestamp'])\n",
    "    df_temp['Date'] = pd.to_datetime(df_temp['Timestamp']).dt.date\n",
    "    df_temp['TS_relative'] = (df_temp['Timestamp'].astype(int) - \n",
    "                             pd.to_datetime(df_temp['Date']).astype(int))/ 10**9\n",
    "    df_temp = df_temp.drop(['Timestamp'], axis = 1)\n",
    "    df_temp = df_temp.drop(['Date'], axis = 1)\n",
    "    df_temp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_temp.fillna(0, inplace=True)\n",
    "    df_temp[cat_cols] = df_temp[cat_cols].astype('category')\n",
    "    X_temp = df_temp.drop(['is_allowed'], axis = 1)\n",
    "    y_temp = df_temp['is_allowed']*1 \n",
    "    \n",
    "    return X_temp, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e60d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df):\n",
    "    stdsc = MinMaxScaler()\n",
    "    stdsc.fit(df)\n",
    "    return stdsc.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d307a8",
   "metadata": {},
   "source": [
    "### Creating Train and Test Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e68f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = transformations([dfs_parquet['Friday-02-03-2018'], \n",
    "                      dfs_parquet['Friday-16-02-2018'], \n",
    "                      dfs_parquet['Friday-23-02-2018'],\n",
    "                      dfs_parquet['Thursday-01-03-2018'],\n",
    "                      dfs_parquet['Thursday-15-02-2018'],\n",
    "                      dfs_parquet['Thursday-22-02-2018'],\n",
    "                      dfs_parquet['Thuesday-20-02-2018'],\n",
    "                      dfs_parquet['Wednesday-14-02-2018'],\n",
    "                      dfs_parquet['Wednesday-21-02-2018']\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b39b2628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15619872, 79)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = scale_data(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ee7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = transformations([dfs_parquet['Wednesday-28-02-2018']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9cde59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613071, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scale_data(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa328dd8",
   "metadata": {},
   "source": [
    "### Preparing data for Pytorch by converting Dataframes into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c762df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872, 79])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn =  torch.from_numpy(X_train_scaled).float()\n",
    "x_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2b60d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15619872])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn = torch.from_numpy(y_train.to_numpy())\n",
    "y_for_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7e6d75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071, 79])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_nn_test =  torch.from_numpy(X_test_scaled).float()\n",
    "x_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb6c8dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([613071])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_nn_test = torch.from_numpy(y_test.to_numpy())\n",
    "y_for_nn_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ec7a1",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "\n",
    "- Layers:\n",
    "1. Linear input=79 out=128\n",
    "2. BayesLinear input=128 out=128\n",
    "3. BayesLinear input=120 out=2 (Benign or Not Benign)\n",
    "\n",
    "- Activation Function = ReLU\n",
    "\n",
    "- Loss Function Hybrid:\n",
    " Cross Entropy and Kullback-Leibler Divergence (KL divergence)\n",
    "\n",
    "- Optimizer = Adam with Learning Rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e738faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=79, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=128),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=128, out_features=2),\n",
    ")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cde6e",
   "metadata": {},
   "source": [
    "### Training with Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e466895",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1048576\n",
    "train_data = TensorDataset(x_for_nn, y_for_nn)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08d4329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 1...... Average Loss for Epoch: 0.1412525773048401\n",
      "F1: 0.9717333804160712\n",
      "Accuracy: 0.9523639678955078\n",
      "Precision: 0.9556840077071291\n",
      "Recall: 0.9883310138100846\n",
      "Epoch 0, Batch 2...... Average Loss for Epoch: 0.1421404480934143\n",
      "F1: 0.9675239022260227\n",
      "Accuracy: 0.945526123046875\n",
      "Precision: 0.9552333981864334\n",
      "Recall: 0.9801347999829513\n",
      "Epoch 0, Batch 3...... Average Loss for Epoch: 0.1426272690296173\n",
      "F1: 0.9686441997730759\n",
      "Accuracy: 0.9475793838500977\n",
      "Precision: 0.9596884311234294\n",
      "Recall: 0.9777686925978176\n",
      "Epoch 0, Batch 4...... Average Loss for Epoch: 0.14221831411123276\n",
      "F1: 0.9722576067259769\n",
      "Accuracy: 0.9532060623168945\n",
      "Precision: 0.9555052748442218\n",
      "Recall: 0.9896078395263505\n",
      "Epoch 0, Batch 5...... Average Loss for Epoch: 0.14204095900058747\n",
      "F1: 0.9704947654380045\n",
      "Accuracy: 0.9503545761108398\n",
      "Precision: 0.955532439934418\n",
      "Recall: 0.9859331238944575\n",
      "Epoch 0, Batch 6...... Average Loss for Epoch: 0.14153132339318594\n",
      "F1: 0.9723808764498697\n",
      "Accuracy: 0.9534177780151367\n",
      "Precision: 0.9559725072767662\n",
      "Recall: 0.989362350891687\n",
      "Epoch 0, Batch 7...... Average Loss for Epoch: 0.1412250761474882\n",
      "F1: 0.9717901832984438\n",
      "Accuracy: 0.9524621963500977\n",
      "Precision: 0.9555917153506863\n",
      "Recall: 0.9885472892065655\n",
      "Epoch 0, Batch 8...... Average Loss for Epoch: 0.14163595996797085\n",
      "F1: 0.9787335847094008\n",
      "Accuracy: 0.9649038314819336\n",
      "Precision: 0.9832102245680356\n",
      "Recall: 0.9742975251300944\n",
      "Epoch 0, Batch 9...... Average Loss for Epoch: 0.14136274490091535\n",
      "F1: 0.970312051409786\n",
      "Accuracy: 0.9500999450683594\n",
      "Precision: 0.9567206562894405\n",
      "Recall: 0.9842951765483231\n",
      "Epoch 0, Batch 10...... Average Loss for Epoch: 0.14145309776067733\n",
      "F1: 0.9725437390012995\n",
      "Accuracy: 0.9536809921264648\n",
      "Precision: 0.9550050348442307\n",
      "Recall: 0.9907386931663741\n",
      "Epoch 0, Batch 11...... Average Loss for Epoch: 0.1411461220546202\n",
      "F1: 0.9700831131591494\n",
      "Accuracy: 0.9496135711669922\n",
      "Precision: 0.9553079728328148\n",
      "Recall: 0.9853224685859417\n",
      "Epoch 0, Batch 12...... Average Loss for Epoch: 0.14070083076755205\n",
      "F1: 0.9710172344653056\n",
      "Accuracy: 0.9512004852294922\n",
      "Precision: 0.9559188097810996\n",
      "Recall: 0.9866002626541884\n",
      "Epoch 0, Batch 13...... Average Loss for Epoch: 0.14161348686768457\n",
      "F1: 0.9625312437068363\n",
      "Accuracy: 0.9396705627441406\n",
      "Precision: 0.9923074010886145\n",
      "Recall: 0.9344900120873927\n",
      "Epoch 0, Batch 14...... Average Loss for Epoch: 0.14141365247113363\n",
      "F1: 0.9795177644238708\n",
      "Accuracy: 0.9662885665893555\n",
      "Precision: 0.9858222533240028\n",
      "Recall: 0.9732933995212087\n",
      "Epoch 0, Batch 15...... Average Loss for Epoch: 0.14120672146479288\n",
      "F1: 0.9724025215970116\n",
      "Accuracy: 0.9534649630562838\n",
      "Precision: 0.9554947071837455\n",
      "Recall: 0.9899194947156362\n",
      "Epoch 1, Batch 1...... Average Loss for Epoch: 0.1479877233505249\n",
      "F1: 0.9640911766428896\n",
      "Accuracy: 0.9386205673217773\n",
      "Precision: 0.9355037799466844\n",
      "Recall: 0.9944808106014478\n",
      "Epoch 1, Batch 2...... Average Loss for Epoch: 0.14155923575162888\n",
      "F1: 0.9736436958048423\n",
      "Accuracy: 0.9556903839111328\n",
      "Precision: 0.9599365553066139\n",
      "Recall: 0.9877479613505441\n",
      "Epoch 1, Batch 3...... Average Loss for Epoch: 0.1396319568157196\n",
      "F1: 0.9797710897980234\n",
      "Accuracy: 0.9666719436645508\n",
      "Precision: 0.9850883339579992\n",
      "Recall: 0.9745109395924468\n",
      "Epoch 1, Batch 4...... Average Loss for Epoch: 0.1383858285844326\n",
      "F1: 0.9734860071549416\n",
      "Accuracy: 0.955775260925293\n",
      "Precision: 0.9665258095499762\n",
      "Recall: 0.980547176178843\n",
      "Epoch 1, Batch 5...... Average Loss for Epoch: 0.14368573427200318\n",
      "F1: 0.9466688184449148\n",
      "Accuracy: 0.9155387878417969\n",
      "Precision: 0.9924333865298371\n",
      "Recall: 0.9049389254095624\n",
      "Epoch 1, Batch 6...... Average Loss for Epoch: 0.14177953700224558\n",
      "F1: 0.9713045151940584\n",
      "Accuracy: 0.9516582489013672\n",
      "Precision: 0.9557653743315508\n",
      "Recall: 0.9873572875425836\n",
      "Epoch 1, Batch 7...... Average Loss for Epoch: 0.14530266182763235\n",
      "F1: 0.9638547368350658\n",
      "Accuracy: 0.9381446838378906\n",
      "Precision: 0.9339262283131652\n",
      "Recall: 0.9957649220863113\n",
      "Epoch 1, Batch 8...... Average Loss for Epoch: 0.14659292250871658\n",
      "F1: 0.969307921745356\n",
      "Accuracy: 0.9478321075439453\n",
      "Precision: 0.945834583436444\n",
      "Recall: 0.993976014526608\n",
      "Epoch 1, Batch 9...... Average Loss for Epoch: 0.1450852503379186\n",
      "F1: 0.9757206099023862\n",
      "Accuracy: 0.959406852722168\n",
      "Precision: 0.9666170144955709\n",
      "Recall: 0.9849973108713352\n",
      "Epoch 1, Batch 10...... Average Loss for Epoch: 0.1438199833035469\n",
      "F1: 0.9817067165363726\n",
      "Accuracy: 0.9698867797851562\n",
      "Precision: 0.9884029668619532\n",
      "Recall: 0.9751005874120723\n",
      "Epoch 1, Batch 11...... Average Loss for Epoch: 0.14283559268171137\n",
      "F1: 0.9727064007776905\n",
      "Accuracy: 0.9541864395141602\n",
      "Precision: 0.9598316301244834\n",
      "Recall: 0.9859312607041626\n",
      "Epoch 1, Batch 12...... Average Loss for Epoch: 0.1478130022684733\n",
      "F1: 0.9423543711336466\n",
      "Accuracy: 0.909088134765625\n",
      "Precision: 0.9926163441731414\n",
      "Recall: 0.8969371932962901\n",
      "Epoch 1, Batch 13...... Average Loss for Epoch: 0.14658139989926264\n",
      "F1: 0.9737593514283066\n",
      "Accuracy: 0.9562664031982422\n",
      "Precision: 0.9680262852514073\n",
      "Recall: 0.979560729523314\n",
      "Epoch 1, Batch 14...... Average Loss for Epoch: 0.14571903113807952\n",
      "F1: 0.9724885199176602\n",
      "Accuracy: 0.9536056518554688\n",
      "Precision: 0.9563957077563605\n",
      "Recall: 0.9891321728866868\n",
      "Epoch 1, Batch 15...... Average Loss for Epoch: 0.1484579175710678\n",
      "F1: 0.9486932590497992\n",
      "Accuracy: 0.9104763951785897\n",
      "Precision: 0.9038192951674936\n",
      "Recall: 0.9982559325883936\n",
      "Epoch 2, Batch 1...... Average Loss for Epoch: 0.14475077390670776\n",
      "F1: 0.9730570468114997\n",
      "Accuracy: 0.9544210433959961\n",
      "Precision: 0.9536634525495985\n",
      "Recall: 0.9932557863856655\n",
      "Epoch 2, Batch 2...... Average Loss for Epoch: 0.13840792328119278\n",
      "F1: 0.9755064468282906\n",
      "Accuracy: 0.9590692520141602\n",
      "Precision: 0.9674997934069068\n",
      "Recall: 0.9836467260075638\n",
      "Epoch 2, Batch 3...... Average Loss for Epoch: 0.13930612802505493\n",
      "F1: 0.9719372308458445\n",
      "Accuracy: 0.9527072906494141\n",
      "Precision: 0.9553528617977891\n",
      "Recall: 0.9891075618192227\n",
      "Epoch 2, Batch 4...... Average Loss for Epoch: 0.14151237905025482\n",
      "F1: 0.9667007162215623\n",
      "Accuracy: 0.9462165832519531\n",
      "Precision: 0.992537241046508\n",
      "Recall: 0.9421751560687255\n",
      "Epoch 2, Batch 5...... Average Loss for Epoch: 0.144230717420578\n",
      "F1: 0.9512203757411879\n",
      "Accuracy: 0.9224786758422852\n",
      "Precision: 0.9922976280650795\n",
      "Recall: 0.9134088127436043\n",
      "Epoch 2, Batch 6...... Average Loss for Epoch: 0.1430443599820137\n",
      "F1: 0.982157620336269\n",
      "Accuracy: 0.9706296920776367\n",
      "Precision: 0.9884955731571926\n",
      "Recall: 0.97590042403372\n",
      "Epoch 2, Batch 7...... Average Loss for Epoch: 0.1415665830884661\n",
      "F1: 0.9756185651873966\n",
      "Accuracy: 0.9591836929321289\n",
      "Precision: 0.9658483489834475\n",
      "Recall: 0.985588466168979\n",
      "Epoch 2, Batch 8...... Average Loss for Epoch: 0.14081484265625477\n",
      "F1: 0.9727001515119833\n",
      "Accuracy: 0.9539308547973633\n",
      "Precision: 0.9555467222425167\n",
      "Recall: 0.9904806955272735\n",
      "Epoch 2, Batch 9...... Average Loss for Epoch: 0.13998579151100582\n",
      "F1: 0.9696231679941684\n",
      "Accuracy: 0.9484949111938477\n",
      "Precision: 0.9479059557887953\n",
      "Recall: 0.992358827701178\n",
      "Epoch 2, Batch 10...... Average Loss for Epoch: 0.1389877900481224\n",
      "F1: 0.9766590732550032\n",
      "Accuracy: 0.9608554840087891\n",
      "Precision: 0.9650415348101266\n",
      "Recall: 0.9885597327457792\n",
      "Epoch 2, Batch 11...... Average Loss for Epoch: 0.1392719867554578\n",
      "F1: 0.9648266894361757\n",
      "Accuracy: 0.9398937225341797\n",
      "Precision: 0.9363739074200652\n",
      "Recall: 0.9950627999415226\n",
      "Epoch 2, Batch 12...... Average Loss for Epoch: 0.1403527669608593\n",
      "F1: 0.9657871779073434\n",
      "Accuracy: 0.9414310455322266\n",
      "Precision: 0.9359412622145441\n",
      "Recall: 0.9975992855400111\n",
      "Epoch 2, Batch 13...... Average Loss for Epoch: 0.14042606835181898\n",
      "F1: 0.9596124754502081\n",
      "Accuracy: 0.9351253509521484\n",
      "Precision: 0.9919042551755203\n",
      "Recall: 0.9293569446504819\n",
      "Epoch 2, Batch 14...... Average Loss for Epoch: 0.14217723267418997\n",
      "F1: 0.9493832222771217\n",
      "Accuracy: 0.9195947647094727\n",
      "Precision: 0.9924114533585532\n",
      "Recall: 0.9099311119448159\n",
      "Epoch 2, Batch 15...... Average Loss for Epoch: 0.1417002926270167\n",
      "F1: 0.9797104238193344\n",
      "Accuracy: 0.966792153290885\n",
      "Precision: 0.9915972468974956\n",
      "Recall: 0.9681052127111469\n",
      "Epoch 3, Batch 1...... Average Loss for Epoch: 0.1340130865573883\n",
      "F1: 0.9804990534791547\n",
      "Accuracy: 0.968022346496582\n",
      "Precision: 0.9916546674572028\n",
      "Recall: 0.9695916374414969\n",
      "Epoch 3, Batch 2...... Average Loss for Epoch: 0.1333438903093338\n",
      "F1: 0.9731707247978018\n",
      "Accuracy: 0.9548406600952148\n",
      "Precision: 0.9582634097137297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9885491833753665\n",
      "Epoch 3, Batch 3...... Average Loss for Epoch: 0.13656889398892721\n",
      "F1: 0.9734179578122083\n",
      "Accuracy: 0.9551849365234375\n",
      "Precision: 0.9569978344313186\n",
      "Recall: 0.990411389381621\n",
      "Epoch 3, Batch 4...... Average Loss for Epoch: 0.14283661916851997\n",
      "F1: 0.9642727854353493\n",
      "Accuracy: 0.9389162063598633\n",
      "Precision: 0.9352918580556502\n",
      "Recall: 0.9951071477088788\n",
      "Epoch 3, Batch 5...... Average Loss for Epoch: 0.14022853076457978\n",
      "F1: 0.9734568637135185\n",
      "Accuracy: 0.9554100036621094\n",
      "Precision: 0.9596433084517809\n",
      "Recall: 0.9876739045038632\n",
      "Epoch 3, Batch 6...... Average Loss for Epoch: 0.13852368791898093\n",
      "F1: 0.9746724494198324\n",
      "Accuracy: 0.9574508666992188\n",
      "Precision: 0.9611701466602027\n",
      "Recall: 0.9885595118417977\n",
      "Epoch 3, Batch 7...... Average Loss for Epoch: 0.14606884121894836\n",
      "F1: 0.9468286216900006\n",
      "Accuracy: 0.9158010482788086\n",
      "Precision: 0.9923699392776438\n",
      "Recall: 0.9052838145822273\n",
      "Epoch 3, Batch 8...... Average Loss for Epoch: 0.14393611811101437\n",
      "F1: 0.9777507524372392\n",
      "Accuracy: 0.9625577926635742\n",
      "Precision: 0.9634313998121538\n",
      "Recall: 0.9925021802007855\n",
      "Epoch 3, Batch 9...... Average Loss for Epoch: 0.14253486030631596\n",
      "F1: 0.968628911569968\n",
      "Accuracy: 0.9466629028320312\n",
      "Precision: 0.9445797947464634\n",
      "Recall: 0.9939346079597191\n",
      "Epoch 3, Batch 10...... Average Loss for Epoch: 0.1411241888999939\n",
      "F1: 0.9805796710333724\n",
      "Accuracy: 0.9676074981689453\n",
      "Precision: 0.9743635485612022\n",
      "Recall: 0.9868756164282665\n",
      "Epoch 3, Batch 11...... Average Loss for Epoch: 0.14113640785217285\n",
      "F1: 0.9837990941591058\n",
      "Accuracy: 0.9733476638793945\n",
      "Precision: 0.990736438000453\n",
      "Recall: 0.976958228225566\n",
      "Epoch 3, Batch 12...... Average Loss for Epoch: 0.14081093048055968\n",
      "F1: 0.9731998327365448\n",
      "Accuracy: 0.9549531936645508\n",
      "Precision: 0.9598242914300104\n",
      "Recall: 0.9869534296012263\n",
      "Epoch 3, Batch 13...... Average Loss for Epoch: 0.1404644434268658\n",
      "F1: 0.9741269928212414\n",
      "Accuracy: 0.956303596496582\n",
      "Precision: 0.9565183640880057\n",
      "Recall: 0.9923960978371046\n",
      "Epoch 3, Batch 14...... Average Loss for Epoch: 0.14029822498559952\n",
      "F1: 0.9741422740986873\n",
      "Accuracy: 0.9564361572265625\n",
      "Precision: 0.9580815987493625\n",
      "Recall: 0.9907505918331629\n",
      "Epoch 3, Batch 15...... Average Loss for Epoch: 0.1408851275841395\n",
      "F1: 0.9645874134232417\n",
      "Accuracy: 0.9394706152746093\n",
      "Precision: 0.9355005421644558\n",
      "Recall: 0.9955410837094072\n",
      "Epoch 4, Batch 1...... Average Loss for Epoch: 0.1272311806678772\n",
      "F1: 0.9737076701877635\n",
      "Accuracy: 0.9557561874389648\n",
      "Precision: 0.9590933094562112\n",
      "Recall: 0.9887743004799668\n",
      "Epoch 4, Batch 2...... Average Loss for Epoch: 0.14706530421972275\n",
      "F1: 0.9479321011411088\n",
      "Accuracy: 0.9174251556396484\n",
      "Precision: 0.9923663064909688\n",
      "Recall: 0.9073065331955031\n",
      "Epoch 4, Batch 3...... Average Loss for Epoch: 0.14593693614006042\n",
      "F1: 0.9564483809367095\n",
      "Accuracy: 0.9303350448608398\n",
      "Precision: 0.9923077113400022\n",
      "Recall: 0.923090378673234\n",
      "Epoch 4, Batch 4...... Average Loss for Epoch: 0.1448025219142437\n",
      "F1: 0.9624546908362976\n",
      "Accuracy: 0.9396142959594727\n",
      "Precision: 0.9924038900104795\n",
      "Recall: 0.9342601780628584\n",
      "Epoch 4, Batch 5...... Average Loss for Epoch: 0.14076090455055237\n",
      "F1: 0.97800139590542\n",
      "Accuracy: 0.9631481170654297\n",
      "Precision: 0.9673104426851654\n",
      "Recall: 0.9889313082562723\n",
      "Epoch 4, Batch 6...... Average Loss for Epoch: 0.14047733694314957\n",
      "F1: 0.9648927938427242\n",
      "Accuracy: 0.9399862289428711\n",
      "Precision: 0.9360759706050132\n",
      "Recall: 0.9955402060668854\n",
      "Epoch 4, Batch 7...... Average Loss for Epoch: 0.1388497416462217\n",
      "F1: 0.9755402046016957\n",
      "Accuracy: 0.9588537216186523\n",
      "Precision: 0.9609439394920891\n",
      "Recall: 0.9905867290840827\n",
      "Epoch 4, Batch 8...... Average Loss for Epoch: 0.14149721525609493\n",
      "F1: 0.9660026529351368\n",
      "Accuracy: 0.9418020248413086\n",
      "Precision: 0.9359938937956602\n",
      "Recall: 0.997999359979372\n",
      "Epoch 4, Batch 9...... Average Loss for Epoch: 0.13977751632531485\n",
      "F1: 0.9777469294487289\n",
      "Accuracy: 0.9628505706787109\n",
      "Precision: 0.9702542717818072\n",
      "Recall: 0.9853562097937687\n",
      "Epoch 4, Batch 10...... Average Loss for Epoch: 0.13861140012741088\n",
      "F1: 0.9747691694338457\n",
      "Accuracy: 0.9579935073852539\n",
      "Precision: 0.9706940316812029\n",
      "Recall: 0.9788786676729374\n",
      "Epoch 4, Batch 11...... Average Loss for Epoch: 0.13875076987526633\n",
      "F1: 0.9625647140721643\n",
      "Accuracy: 0.9397916793823242\n",
      "Precision: 0.9923962043377949\n",
      "Recall: 0.9344743580296946\n",
      "Epoch 4, Batch 12...... Average Loss for Epoch: 0.13905993476510048\n",
      "F1: 0.9748321696078673\n",
      "Accuracy: 0.9589767456054688\n",
      "Precision: 0.9917512297560488\n",
      "Recall: 0.9584806974994304\n",
      "Epoch 4, Batch 13...... Average Loss for Epoch: 0.13844154316645402\n",
      "F1: 0.9774987192192336\n",
      "Accuracy: 0.9623441696166992\n",
      "Precision: 0.9676986956717967\n",
      "Recall: 0.9874992659834267\n",
      "Epoch 4, Batch 14...... Average Loss for Epoch: 0.1386635143842016\n",
      "F1: 0.9656251915500649\n",
      "Accuracy: 0.9411697387695312\n",
      "Precision: 0.9356309054586686\n",
      "Recall: 0.9976062727398333\n",
      "Epoch 4, Batch 15...... Average Loss for Epoch: 0.1379771629969279\n",
      "F1: 0.970267459333806\n",
      "Accuracy: 0.949535437025435\n",
      "Precision: 0.9474768746671237\n",
      "Recall: 0.9941814752767301\n",
      "Epoch 5, Batch 1...... Average Loss for Epoch: 0.1289757788181305\n",
      "F1: 0.9853281003982588\n",
      "Accuracy: 0.9758281707763672\n",
      "Precision: 0.9907927394306842\n",
      "Recall: 0.979923410291483\n",
      "Epoch 5, Batch 2...... Average Loss for Epoch: 0.13573863357305527\n",
      "F1: 0.9655976273534103\n",
      "Accuracy: 0.9411153793334961\n",
      "Precision: 0.9360842962207568\n",
      "Recall: 0.9970325658352711\n",
      "Epoch 5, Batch 3...... Average Loss for Epoch: 0.13129668682813644\n",
      "F1: 0.9769049350578737\n",
      "Accuracy: 0.9611129760742188\n",
      "Precision: 0.9621884929843979\n",
      "Recall: 0.9920785381992536\n",
      "Epoch 5, Batch 4...... Average Loss for Epoch: 0.13186832703649998\n",
      "F1: 0.9752405251314058\n",
      "Accuracy: 0.959686279296875\n",
      "Precision: 0.9925284697848313\n",
      "Recall: 0.958544515855672\n",
      "Epoch 5, Batch 5...... Average Loss for Epoch: 0.13306958824396134\n",
      "F1: 0.969705681193605\n",
      "Accuracy: 0.9509572982788086\n",
      "Precision: 0.992784303507972\n",
      "Recall: 0.9476756704475715\n",
      "Epoch 5, Batch 6...... Average Loss for Epoch: 0.13232549900809923\n",
      "F1: 0.9794157638365211\n",
      "Accuracy: 0.9662885665893555\n",
      "Precision: 0.9916069832540568\n",
      "Recall: 0.9675206713307309\n",
      "Epoch 5, Batch 7...... Average Loss for Epoch: 0.1321120804974011\n",
      "F1: 0.9762680026465816\n",
      "Accuracy: 0.9600467681884766\n",
      "Precision: 0.960396105813973\n",
      "Recall: 0.9926733259528996\n",
      "Epoch 5, Batch 8...... Average Loss for Epoch: 0.13294905703514814\n",
      "F1: 0.9645905531666106\n",
      "Accuracy: 0.9394683837890625\n",
      "Precision: 0.9358425616211477\n",
      "Recall: 0.9951607296201564\n",
      "Epoch 5, Batch 9...... Average Loss for Epoch: 0.1351287853386667\n",
      "F1: 0.9749183828819079\n",
      "Accuracy: 0.9576730728149414\n",
      "Precision: 0.957349990233161\n",
      "Recall: 0.993143626911984\n",
      "Epoch 5, Batch 10...... Average Loss for Epoch: 0.13515404537320136\n",
      "F1: 0.9748387239294661\n",
      "Accuracy: 0.957636833190918\n",
      "Precision: 0.9591213019301352\n",
      "Recall: 0.9910798608711676\n",
      "Epoch 5, Batch 11...... Average Loss for Epoch: 0.13512221452864734\n",
      "F1: 0.9778831194059541\n",
      "Accuracy: 0.9638433456420898\n",
      "Precision: 0.9916904488080532\n",
      "Recall: 0.9644549899371605\n",
      "Epoch 5, Batch 12...... Average Loss for Epoch: 0.1342775591959556\n",
      "F1: 0.975300961173803\n",
      "Accuracy: 0.9588832855224609\n",
      "Precision: 0.9712558561971287\n",
      "Recall: 0.9793799013291116\n",
      "Epoch 5, Batch 13...... Average Loss for Epoch: 0.136616645524135\n",
      "F1: 0.9477183235503945\n",
      "Accuracy: 0.9171123504638672\n",
      "Precision: 0.9924184587474961\n",
      "Recall: 0.9068713679188808\n",
      "Epoch 5, Batch 14...... Average Loss for Epoch: 0.13557749880211695\n",
      "F1: 0.9790548457034783\n",
      "Accuracy: 0.9649991989135742\n",
      "Precision: 0.9703829737168689\n",
      "Recall: 0.9878831084473887\n",
      "Epoch 5, Batch 15...... Average Loss for Epoch: 0.13500479161739348\n",
      "F1: 0.9753176174013162\n",
      "Accuracy: 0.9583478753107018\n",
      "Precision: 0.9580450678892218\n",
      "Recall: 0.9932244136857598\n",
      "Epoch 6, Batch 1...... Average Loss for Epoch: 0.1258286088705063\n",
      "F1: 0.979632091101901\n",
      "Accuracy: 0.9658479690551758\n",
      "Precision: 0.9684118436188911\n",
      "Recall: 0.9911153871826801\n",
      "Epoch 6, Batch 2...... Average Loss for Epoch: 0.12465649470686913\n",
      "F1: 0.9772441793606619\n",
      "Accuracy: 0.961766242980957\n",
      "Precision: 0.963843415891968\n",
      "Recall: 0.9910228308820144\n",
      "Epoch 6, Batch 3...... Average Loss for Epoch: 0.13244968404372534\n",
      "F1: 0.9660497659132502\n",
      "Accuracy: 0.9418458938598633\n",
      "Precision: 0.9359579605108432\n",
      "Recall: 0.998140799893234\n",
      "Epoch 6, Batch 4...... Average Loss for Epoch: 0.12920734845101833\n",
      "F1: 0.9789585090810736\n",
      "Accuracy: 0.9650564193725586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9776711312169446\n",
      "Recall: 0.9802492818025205\n",
      "Epoch 6, Batch 5...... Average Loss for Epoch: 0.12780059427022933\n",
      "F1: 0.9829391288082866\n",
      "Accuracy: 0.9716424942016602\n",
      "Precision: 0.9799002678057659\n",
      "Recall: 0.9859968966406365\n",
      "Epoch 6, Batch 6...... Average Loss for Epoch: 0.12601666276653609\n",
      "F1: 0.9789071325064753\n",
      "Accuracy: 0.9647407531738281\n",
      "Precision: 0.970848209486412\n",
      "Recall: 0.9871009682040189\n",
      "Epoch 6, Batch 7...... Average Loss for Epoch: 0.12530323650155747\n",
      "F1: 0.9851538110367661\n",
      "Accuracy: 0.9754371643066406\n",
      "Precision: 0.9867748726043675\n",
      "Recall: 0.9835380668536565\n",
      "Epoch 6, Batch 8...... Average Loss for Epoch: 0.12401741091161966\n",
      "F1: 0.9789489193489253\n",
      "Accuracy: 0.9648456573486328\n",
      "Precision: 0.9711963160292162\n",
      "Recall: 0.9868262893933323\n",
      "Epoch 6, Batch 9...... Average Loss for Epoch: 0.123111459116141\n",
      "F1: 0.986149414507976\n",
      "Accuracy: 0.9771823883056641\n",
      "Precision: 0.9916131037686315\n",
      "Recall: 0.9807456040862337\n",
      "Epoch 6, Batch 10...... Average Loss for Epoch: 0.12323888763785362\n",
      "F1: 0.9843962452649786\n",
      "Accuracy: 0.9743356704711914\n",
      "Precision: 0.9914284846672771\n",
      "Recall: 0.9774630631211562\n",
      "Epoch 6, Batch 11...... Average Loss for Epoch: 0.12263023582371799\n",
      "F1: 0.9795586943785554\n",
      "Accuracy: 0.9658603668212891\n",
      "Precision: 0.9707714856460549\n",
      "Recall: 0.9885064359579256\n",
      "Epoch 6, Batch 12...... Average Loss for Epoch: 0.12271742646892865\n",
      "F1: 0.9760803502271969\n",
      "Accuracy: 0.9596223831176758\n",
      "Precision: 0.9583141509130463\n",
      "Recall: 0.9945177281612861\n",
      "Epoch 6, Batch 13...... Average Loss for Epoch: 0.12212201952934265\n",
      "F1: 0.9798576154546629\n",
      "Accuracy: 0.9662694931030273\n",
      "Precision: 0.9698074453849909\n",
      "Recall: 0.9901182677390099\n",
      "Epoch 6, Batch 14...... Average Loss for Epoch: 0.12225149997643062\n",
      "F1: 0.9758670536306562\n",
      "Accuracy: 0.9606904983520508\n",
      "Precision: 0.9924487632929632\n",
      "Recall: 0.9598303286892166\n",
      "Epoch 6, Batch 15...... Average Loss for Epoch: 0.12192465017239253\n",
      "F1: 0.9883472854552101\n",
      "Accuracy: 0.9806992492083489\n",
      "Precision: 0.988655320702144\n",
      "Recall: 0.988039442097516\n",
      "Epoch 7, Batch 1...... Average Loss for Epoch: 0.13061103224754333\n",
      "F1: 0.9696793153458967\n",
      "Accuracy: 0.9484806060791016\n",
      "Precision: 0.9449948255906813\n",
      "Recall: 0.9956879758960042\n",
      "Epoch 7, Batch 2...... Average Loss for Epoch: 0.13566897809505463\n",
      "F1: 0.9626839786284472\n",
      "Accuracy: 0.9399805068969727\n",
      "Precision: 0.9925758826226502\n",
      "Recall: 0.9345398576668132\n",
      "Epoch 7, Batch 3...... Average Loss for Epoch: 0.12916266669829687\n",
      "F1: 0.9849468518233236\n",
      "Accuracy: 0.9752120971679688\n",
      "Precision: 0.9913403662740609\n",
      "Recall: 0.9786352771118725\n",
      "Epoch 7, Batch 4...... Average Loss for Epoch: 0.1258798986673355\n",
      "F1: 0.9779063139992165\n",
      "Accuracy: 0.9631061553955078\n",
      "Precision: 0.9709472041588888\n",
      "Recall: 0.984965900619403\n",
      "Epoch 7, Batch 5...... Average Loss for Epoch: 0.1229830726981163\n",
      "F1: 0.9797363514948743\n",
      "Accuracy: 0.9660835266113281\n",
      "Precision: 0.9706978524403779\n",
      "Recall: 0.9889447536754007\n",
      "Epoch 7, Batch 6...... Average Loss for Epoch: 0.1219509020447731\n",
      "F1: 0.9802340034356337\n",
      "Accuracy: 0.966893196105957\n",
      "Precision: 0.9699939149444456\n",
      "Recall: 0.9906926050692905\n",
      "Epoch 7, Batch 7...... Average Loss for Epoch: 0.12424599485737937\n",
      "F1: 0.9693672785161782\n",
      "Accuracy: 0.9477367401123047\n",
      "Precision: 0.942678289154688\n",
      "Recall: 0.9976115309212403\n",
      "Epoch 7, Batch 8...... Average Loss for Epoch: 0.1228383220732212\n",
      "F1: 0.9861036185695665\n",
      "Accuracy: 0.9771041870117188\n",
      "Precision: 0.9915490793618275\n",
      "Recall: 0.9807176426431613\n",
      "Epoch 7, Batch 9...... Average Loss for Epoch: 0.12546610335508981\n",
      "F1: 0.963789686947404\n",
      "Accuracy: 0.941706657409668\n",
      "Precision: 0.9925255401779668\n",
      "Recall: 0.9366709500911955\n",
      "Epoch 7, Batch 10...... Average Loss for Epoch: 0.12421789690852165\n",
      "F1: 0.9865905453916353\n",
      "Accuracy: 0.9778242111206055\n",
      "Precision: 0.9886001560197625\n",
      "Recall: 0.98458908839779\n",
      "Epoch 7, Batch 11...... Average Loss for Epoch: 0.12300962074236436\n",
      "F1: 0.979668737839489\n",
      "Accuracy: 0.966008186340332\n",
      "Precision: 0.9708815249465794\n",
      "Recall: 0.9886164653710529\n",
      "Epoch 7, Batch 12...... Average Loss for Epoch: 0.1224113404750824\n",
      "F1: 0.980177479580395\n",
      "Accuracy: 0.9668035507202148\n",
      "Precision: 0.9698927227504629\n",
      "Recall: 0.990682693569516\n",
      "Epoch 7, Batch 13...... Average Loss for Epoch: 0.12173856450961186\n",
      "F1: 0.9801193770897537\n",
      "Accuracy: 0.9666919708251953\n",
      "Precision: 0.9694775543756722\n",
      "Recall: 0.9909974204346239\n",
      "Epoch 7, Batch 14...... Average Loss for Epoch: 0.12171679841620582\n",
      "F1: 0.9859213957621206\n",
      "Accuracy: 0.9768056869506836\n",
      "Precision: 0.9914430110356052\n",
      "Recall: 0.980460942608984\n",
      "Epoch 7, Batch 15...... Average Loss for Epoch: 0.12123874773581823\n",
      "F1: 0.9805479446843075\n",
      "Accuracy: 0.9673582263611291\n",
      "Precision: 0.9679200216320154\n",
      "Recall: 0.9935097225666599\n",
      "Epoch 8, Batch 1...... Average Loss for Epoch: 0.11531305313110352\n",
      "F1: 0.9826038993462382\n",
      "Accuracy: 0.9714260101318359\n",
      "Precision: 0.9916362562490771\n",
      "Recall: 0.9737346003631702\n",
      "Epoch 8, Batch 2...... Average Loss for Epoch: 0.1212778240442276\n",
      "F1: 0.9753499799074218\n",
      "Accuracy: 0.959869384765625\n",
      "Precision: 0.9925201154529837\n",
      "Recall: 0.9587638126716687\n",
      "Epoch 8, Batch 3...... Average Loss for Epoch: 0.11776050925254822\n",
      "F1: 0.9780391959810472\n",
      "Accuracy: 0.9633216857910156\n",
      "Precision: 0.9711431062890293\n",
      "Recall: 0.9850339244082063\n",
      "Epoch 8, Batch 4...... Average Loss for Epoch: 0.11833719536662102\n",
      "F1: 0.9801729773818469\n",
      "Accuracy: 0.966710090637207\n",
      "Precision: 0.9672333294098524\n",
      "Recall: 0.9934635330312074\n",
      "Epoch 8, Batch 5...... Average Loss for Epoch: 0.11765609830617904\n",
      "F1: 0.9808655896622123\n",
      "Accuracy: 0.9678936004638672\n",
      "Precision: 0.9690809526269567\n",
      "Recall: 0.9929403723248786\n",
      "Epoch 8, Batch 6...... Average Loss for Epoch: 0.11641253903508186\n",
      "F1: 0.9804198592873217\n",
      "Accuracy: 0.9672222137451172\n",
      "Precision: 0.9708942711494936\n",
      "Recall: 0.990134213360581\n",
      "Epoch 8, Batch 7...... Average Loss for Epoch: 0.12216007390192576\n",
      "F1: 0.9580815795395153\n",
      "Accuracy: 0.9328441619873047\n",
      "Precision: 0.9922994116972491\n",
      "Recall: 0.9261449755727036\n",
      "Epoch 8, Batch 8...... Average Loss for Epoch: 0.12082461267709732\n",
      "F1: 0.9863093318729337\n",
      "Accuracy: 0.9774465560913086\n",
      "Precision: 0.9914641527001862\n",
      "Recall: 0.9812078356932483\n",
      "Epoch 8, Batch 9...... Average Loss for Epoch: 0.1200380523999532\n",
      "F1: 0.9793845593735239\n",
      "Accuracy: 0.9653310775756836\n",
      "Precision: 0.9655009324978868\n",
      "Recall: 0.9936732967785367\n",
      "Epoch 8, Batch 10...... Average Loss for Epoch: 0.11898954361677169\n",
      "F1: 0.9802983958828115\n",
      "Accuracy: 0.9670257568359375\n",
      "Precision: 0.9707457283211097\n",
      "Recall: 0.9900409388426404\n",
      "Epoch 8, Batch 11...... Average Loss for Epoch: 0.11815995926206763\n",
      "F1: 0.9795222369063284\n",
      "Accuracy: 0.9657907485961914\n",
      "Precision: 0.971065558926065\n",
      "Recall: 0.9881275015117049\n",
      "Epoch 8, Batch 12...... Average Loss for Epoch: 0.11891890441377957\n",
      "F1: 0.9810687866291415\n",
      "Accuracy: 0.9682331085205078\n",
      "Precision: 0.9693388439033703\n",
      "Recall: 0.9930860941782359\n",
      "Epoch 8, Batch 13...... Average Loss for Epoch: 0.11843614796033272\n",
      "F1: 0.9865650610605423\n",
      "Accuracy: 0.9778499603271484\n",
      "Precision: 0.9915481068410453\n",
      "Recall: 0.9816318496383234\n",
      "Epoch 8, Batch 14...... Average Loss for Epoch: 0.11893874779343605\n",
      "F1: 0.9678716661392628\n",
      "Accuracy: 0.9481010437011719\n",
      "Precision: 0.9925844302096073\n",
      "Recall: 0.944359575208352\n",
      "Epoch 8, Batch 15...... Average Loss for Epoch: 0.1188394953807195\n",
      "F1: 0.9811077249893879\n",
      "Accuracy: 0.9683179968674452\n",
      "Precision: 0.9689209105537815\n",
      "Recall: 0.9936050090668531\n",
      "Epoch 9, Batch 1...... Average Loss for Epoch: 0.11364661902189255\n",
      "F1: 0.9850407444787566\n",
      "Accuracy: 0.9753904342651367\n",
      "Precision: 0.9914867744502872\n",
      "Recall: 0.9786779892572084\n",
      "Epoch 9, Batch 2...... Average Loss for Epoch: 0.11389900371432304\n",
      "F1: 0.9806850001959155\n",
      "Accuracy: 0.9675626754760742\n",
      "Precision: 0.968090759875148\n",
      "Recall: 0.993611245680514\n",
      "Epoch 9, Batch 3...... Average Loss for Epoch: 0.1122826486825943\n",
      "F1: 0.9803903245106698\n",
      "Accuracy: 0.9671802520751953\n",
      "Precision: 0.9705934119494727\n",
      "Recall: 0.9903870285902433\n",
      "Epoch 9, Batch 4...... Average Loss for Epoch: 0.11162151023745537\n",
      "F1: 0.9812110556970806\n",
      "Accuracy: 0.9685373306274414\n",
      "Precision: 0.9704157809537649\n",
      "Recall: 0.9922492138636442\n",
      "Epoch 9, Batch 5...... Average Loss for Epoch: 0.11270738840103149\n",
      "F1: 0.9814122846170813\n",
      "Accuracy: 0.969538688659668\n",
      "Precision: 0.9920912808783596\n",
      "Recall: 0.9709607401735285\n",
      "Epoch 9, Batch 6...... Average Loss for Epoch: 0.11265327036380768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9854336545589325\n",
      "Accuracy: 0.97601318359375\n",
      "Precision: 0.9915943664073026\n",
      "Recall: 0.9793490222441189\n",
      "Epoch 9, Batch 7...... Average Loss for Epoch: 0.11272499923195158\n",
      "F1: 0.9810005709448826\n",
      "Accuracy: 0.9681692123413086\n",
      "Precision: 0.9709639325346386\n",
      "Recall: 0.9912468695681184\n",
      "Epoch 9, Batch 8...... Average Loss for Epoch: 0.11177975684404373\n",
      "F1: 0.9812451012368363\n",
      "Accuracy: 0.9685773849487305\n",
      "Precision: 0.9713290164957887\n",
      "Recall: 0.9913657364542586\n",
      "Epoch 9, Batch 9...... Average Loss for Epoch: 0.11111328999201457\n",
      "F1: 0.9808702786783433\n",
      "Accuracy: 0.9679813385009766\n",
      "Precision: 0.971212769150397\n",
      "Recall: 0.990721781197018\n",
      "Epoch 9, Batch 10...... Average Loss for Epoch: 0.1108691781759262\n",
      "F1: 0.986597648430263\n",
      "Accuracy: 0.9778957366943359\n",
      "Precision: 0.9914834072879162\n",
      "Recall: 0.9817598048241576\n",
      "Epoch 9, Batch 11...... Average Loss for Epoch: 0.11092777347022836\n",
      "F1: 0.9814276414967005\n",
      "Accuracy: 0.9688997268676758\n",
      "Precision: 0.970904604151173\n",
      "Recall: 0.992181283674313\n",
      "Epoch 9, Batch 12...... Average Loss for Epoch: 0.11053891417880853\n",
      "F1: 0.9867725816546942\n",
      "Accuracy: 0.9781932830810547\n",
      "Precision: 0.9915943720658777\n",
      "Recall: 0.9819974578144574\n",
      "Epoch 9, Batch 13...... Average Loss for Epoch: 0.11018397830999814\n",
      "F1: 0.9869179136674837\n",
      "Accuracy: 0.9784278869628906\n",
      "Precision: 0.9914281531196549\n",
      "Recall: 0.9824485246535878\n",
      "Epoch 9, Batch 14...... Average Loss for Epoch: 0.11010981617229325\n",
      "F1: 0.9814216864180001\n",
      "Accuracy: 0.9688549041748047\n",
      "Precision: 0.9702632964244418\n",
      "Recall: 0.9928397136345848\n",
      "Epoch 9, Batch 15...... Average Loss for Epoch: 0.10975813368956248\n",
      "F1: 0.9868934494345485\n",
      "Accuracy: 0.97838494671252\n",
      "Precision: 0.9916060850049204\n",
      "Recall: 0.9822253958509656\n"
     ]
    }
   ],
   "source": [
    "kl_weight = 0.1\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.process_time()\n",
    "    avg_loss = 0.\n",
    "    counter = 0\n",
    "    for x, y in train_loader:\n",
    "        counter += 1\n",
    "        pre = model(x)\n",
    "        ce = ce_loss(pre, y)\n",
    "        kl = kl_loss(model)\n",
    "        cost = ce + kl_weight*kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += cost.item()\n",
    "        if epoch%1 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {counter}...... Average Loss for Epoch: {avg_loss/counter}\")\n",
    "            _, predicted = torch.max(pre.data, 1)\n",
    "            print(f'F1: {f1_score(y, predicted)}')\n",
    "            print(f'Accuracy: {accuracy_score(y, predicted)}')\n",
    "            print(f'Precision: {precision_score(y, predicted)}')\n",
    "            print(f'Recall: {recall_score(y, predicted)}')            \n",
    "    current_time = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "844af5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9144171274281725\n",
      "Accuracy: 0.8430866897961248\n",
      "Precision: 0.8863109969043451\n",
      "Recall: 0.9443642043366409\n"
     ]
    }
   ],
   "source": [
    "pre_test = model(x_for_nn_test)\n",
    "_, predicted_test = torch.max(pre_test.data, 1)\n",
    "print(f'F1: {f1_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Accuracy: {accuracy_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Precision: {precision_score(y_for_nn_test, predicted_test)}')\n",
    "print(f'Recall: {recall_score(y_for_nn_test, predicted_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b89ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
